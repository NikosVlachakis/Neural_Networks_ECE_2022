{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kChJDbhknE1X"
      },
      "source": [
        "### Dataset review\n",
        "\n",
        "- **Dataset presentation:** The dataset consists of online poker games. There are multiple columns represent the features of the game and the column named result is the label of the dataset which indicates the performance of the player.\n",
        "\n",
        "- **File conversion:** We did not need to convert the data format, we used the read_csv function from pandas.\n",
        "\n",
        "- **Entry count:** The dataset consists of 102615 entries. After carefully examining the dataset, we found that there was just one player with id=fa538846 who had sufficient data to be considered. All the others had missing data essential for the analysis. Therefore, we decided to remove all the players except for the one. This resulted in a dataset with 41303 entries.\n",
        "\n",
        "- **Attribute count:** The dataset consists of 35 attributes with many different types. There are categorical, nominal, numerical and binary data types. More precisely all the columns related to card values such as cards, board_flop, board_turn etc are ordinal because they have a natural order. Other columns that describe some actions of the game such as call, raise etc are nominal and we used one hot encoding to replace them with binary features. There is one binary column called all_in and the rest of them are numerical. The label column with name result is categorical. During the analysis we understood that there are some columns that are not useful and we decided to remove them. The dropped columns are: buyin, tourn_id, table, hand_id, date, time, table_size, seat, name and combination. Additionally, we decided to remove the column with name balance because it provides information on the final result (which is what we want to predict) and we do not want to use it as a feature.\n",
        "\n",
        "- **Indexes and headers:** There are row indexes and column headers.\n",
        "\n",
        "- **Class labels:** Class labels (found in column 34) are categorical and represent if the player won, lost, gave up or took chips. \n",
        "\n",
        "- **Missing values:** There is just one column with missing values, the column named combination in which the 82% are missing values. Considering the content of the column which is the cards combination of each player we thought that the replication of missing rows does not make any sense. Apart from this, the big amount of missing values was another indication that this column should be removed from the training process.\n",
        "\n",
        "- **Class count:** As we can see from the table below, the dataset is not balanced.\n",
        "\n",
        "Class      | Number of instances | Percentages |\n",
        "----------- | ----------- | ----------- |\n",
        "won      | 4228       | 10.2% |\n",
        "lost         | 3570       | 8.6% |\n",
        "gave up   | 21359        | 51.7% |\n",
        "took chips         | 12146       | 29.5% |\n",
        "    \n",
        "\n",
        "\n",
        "      \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdcAWbV7nE1d",
        "outputId": "a3aa8657-90bc-4716-b8f5-afdaa3702069"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import matplotlib as mpl\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from tqdm.notebook import tqdm \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "df = pd.read_csv(\"/content/drive/My Drive/one_dollar_spin_and_go.csv\")\n",
        "\n",
        "# keep rows with name = fa538846\n",
        "df = df[df['name'] == 'fa538846']\n",
        "\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "# drop columns\n",
        "df = df.drop(['buyin', 'tourn_id', 'table', 'hand_id', 'date', 'time','table_size' ,'seat', 'name', 'combination','balance'], axis=1)\n",
        "\n",
        "\n",
        "# From column 'cards' we create 5 new columns for each card x={1,2} ('card_value_x', 'card_suit__c', 'card_suit__d', 'card_suit__h', 'card_suit__s')\n",
        "# We will use OrdinalEncoder to transform the values of the columns 'card_value_x' into numerical values\n",
        "# We will use OneHotEncoder to transform the values of the columns 'card_suit_x' into several columns with binary values\n",
        "\n",
        "df['card_value_1'] = df['cards'].str.split(' ').str[0].str[0]\n",
        "df['card_suit_1'] = df['cards'].str.split(' ').str[0].str[1]\n",
        "df['card_value_2'] = df['cards'].str.split(' ').str[1].str[0]\n",
        "df['card_suit_2'] = df['cards'].str.split(' ').str[1].str[1]\n",
        "\n",
        "\n",
        "# define ordinal encoder with playing card values as categories\n",
        "ordinal_encoder_cards = OrdinalEncoder(categories=[['0','2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']])\n",
        "\n",
        "# fit and transform the card_value_1 and card_value_2 columns\n",
        "df['card_value_1'] = ordinal_encoder_cards.fit_transform(df[['card_value_1']])\n",
        "df['card_value_2'] = ordinal_encoder_cards.fit_transform(df[['card_value_2']])\n",
        "\n",
        "\n",
        "# define one hot encoder for card_suit_1 and card_suit_2\n",
        "one_hot_encoder = sk.preprocessing.OneHotEncoder(sparse=False)\n",
        "\n",
        "\n",
        "# use one hot encoder to transform card_suit_1 and card_suit_2 and save the result in new columns\n",
        "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['card_suit_1', 'card_suit_2']]))\n",
        "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
        "\n",
        "df = pd.concat([df, oneHotEncodedDf], axis=1 )\n",
        "\n",
        "\n",
        "# do the same as above for the columns board_flop, board_turn and board_river if values is not 0\n",
        "# replace 0 with \"00 00 00\"\n",
        "df['board_flop'] = df['board_flop'].replace('0', '00 00 00')\n",
        "\n",
        "df['board_flop_1'] = df['board_flop'].str.split(' ').str[0].str[0]\n",
        "df['board_flop_suit_1'] = df['board_flop'].str.split(' ').str[0].str[1]\n",
        "df['board_flop_2'] = df['board_flop'].str.split(' ').str[1].str[0]\n",
        "df['board_flop_suit_2'] = df['board_flop'].str.split(' ').str[1].str[1]\n",
        "df['board_flop_3'] = df['board_flop'].str.split(' ').str[2].str[0]\n",
        "df['board_flop_suit_3'] = df['board_flop'].str.split(' ').str[2].str[1]\n",
        "\n",
        "df['board_flop_1'] = ordinal_encoder_cards.fit_transform(df[['board_flop_1']])\n",
        "df['board_flop_2'] = ordinal_encoder_cards.fit_transform(df[['board_flop_2']])\n",
        "df['board_flop_3'] = ordinal_encoder_cards.fit_transform(df[['board_flop_3']])\n",
        "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['board_flop_suit_1', 'board_flop_suit_2', 'board_flop_suit_3']]))\n",
        "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
        "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
        "\n",
        "# replace 0 with \"00\"\n",
        "df['board_turn'] = df['board_turn'].replace('0', '00')\n",
        "\n",
        "df['board_turn_value'] = df['board_turn'].str.split(' ').str[0].str[0]\n",
        "df['board_turn_suit'] = df['board_turn'].str.split(' ').str[0].str[1]\n",
        "df['board_turn_value'] = ordinal_encoder_cards.fit_transform(df[['board_turn_value']])\n",
        "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['board_turn_suit']]))\n",
        "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
        "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
        "\n",
        "# replace 0 with \"00\"\n",
        "df['board_river'] = df['board_river'].replace('0', '00')\n",
        "\n",
        "df['board_river_value'] = df['board_river'].str.split(' ').str[0].str[0]\n",
        "df['board_river_suit'] = df['board_river'].str.split(' ').str[0].str[1]\n",
        "df['board_river_value'] = ordinal_encoder_cards.fit_transform(df[['board_river_value']])\n",
        "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['board_river_suit']]))\n",
        "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
        "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
        "\n",
        "# drop the columns\n",
        "df = df.drop(['cards', 'card_suit_1', 'card_suit_2', 'board_flop', 'board_turn', 'board_river', 'board_flop_suit_1', 'board_flop_suit_2', 'board_flop_suit_3', 'board_turn_suit', 'board_river_suit'], axis=1)\n",
        "\n",
        "\n",
        "# use one hot on the columns 'position', 'action_pre', 'action_flop', 'action_turn', 'action_river'\n",
        "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['position', 'action_pre', 'action_flop', 'action_turn', 'action_river']]))\n",
        "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
        "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
        "df = df.drop(['position', 'action_pre', 'action_flop', 'action_turn', 'action_river'], axis=1)\n",
        "\n",
        "# use label encoder on the column 'result'\n",
        "label_encoder = sk.preprocessing.LabelEncoder()\n",
        "df['result'] = label_encoder.fit_transform(df['result'])\n",
        "\n",
        "y= df['result']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavS9F__tUmI"
      },
      "source": [
        "### Dataset split\n",
        "\n",
        "- **Splitting method:** We used the train_test_split function from sklearn.model_selection to split the dataset into training and testing sets. We used a 70/30 split, meaning that 70% of the dataset was used for training and 30% for testing. We selected this ratio because we wanted to have a good amount of data for training and at the same time we wanted to have enough data for testing.\n",
        "\n",
        "- **Cross validation:**  We used 10 fold cross validation because we undersampled the classes to make the dataset balanced. This way we weren't too concerned about a class not being present in our training set and we used 5 folds to save time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AcStrfksnE1g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X = df.drop(['result'], axis=1)\n",
        "y= df['result']\n",
        "\n",
        "#split the df into train and test sets with 30% of the data in the test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjDHo0jLu2zX"
      },
      "source": [
        "### Dataset metrics\n",
        "\n",
        "- **Metric selection:** We used the accuracy score and the f1_micro as the metrics for evaluating the performance of the models. As about the accuracy score it is considered the most common metric for classification problems. It is also easy to understand and interpret. The accuracy score is the ratio of the number of correct predictions to the total number of predictions. It is a good metric for our problem because we want to know how many times the model predicted the correct class. The f1_micro is the harmonic mean of the precision and recall. It is a good metric for our problem because we want to know how many times the model predicted the correct class and how many times it predicted the wrong class. The f1_micro is a good metric for our problem because we want to know how many times the model predicted the correct class and how many times it predicted the wrong class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HmZRP-tBnE1g"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BJiKu-mWnE1g"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# create a list of models\n",
        "models = []\n",
        "models.append(DummyClassifier())\n",
        "models.append(MLPClassifier())\n",
        "models.append(SVC())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qaaF1EFwdI2"
      },
      "source": [
        "### Out of the box performance\n",
        "\n",
        "- **OOB classifiers:** As we can see from the below results the MLPClassifier has better performance metrics in comparison with the SVC classifier but both of them have very good performance metrics even without tuning the hyperparameters. This shows that the default hyperparameters may be good enough for this dataset's analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "Nbt_baAOnE1g",
        "outputId": "c798da79-6427-4794-e612-79804ad54c26"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "|                 |   Accuracy OOB |   F1 Score OOB |\n",
              "|:----------------|---------------:|---------------:|\n",
              "| DummyClassifier |       0.514002 |       0.349006 |\n",
              "| MLPClassifier   |       0.931321 |       0.931051 |\n",
              "| SVC             |       0.838996 |       0.812634 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
        "out_of_the_box_df = pd.DataFrame(columns=['Accuracy OOB', 'F1 Score OOB'])\n",
        "for clf in models:\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    out_of_the_box_df.loc[clf.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
        "\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "\n",
        "# display the results of the classifiers in a comparison bar plot\n",
        "comparisonBarPlot = out_of_the_box_df.plot.bar()\n",
        "\n",
        "# display the results of the classifiers in a markdown table\n",
        "markDownTableResults = out_of_the_box_df.to_markdown()\n",
        "md(markDownTableResults)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2cCy5U6nE1h"
      },
      "source": [
        "### **MLP Classifier training**\n",
        "\n",
        "#### **Data preprocessing:** We tested a combination of data preprocessing techniques, including:\n",
        "\n",
        "- **Standardization:** We used the MinMaxScaler for standarisizing the data. We did not use the StandardScaler because it is sensitive to outliers.\n",
        "\n",
        "- **Feature selection:** We used the VarianceThreshold to remove features with low variance. We tested thresholds from 0.0 to 0.1 and we found that 0.0 is the best option.\n",
        "\n",
        "- **Sampling:** We used the RandomUnderSampler undersample the majority classes. We avoided using the oversampling techniques because we had a large volume of data and we wanted to avoid overfitting and large training times.\n",
        "\n",
        "- **Feature extraction:** We used the PCA to reduce the dimensionality of the data. We tested the number of components from 1% to 99% and we found that 99% is the best option. In the end we found out that PCA does not make a differenence so we removed it.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "#### **MLP Classifier:** We used the MLPClassifier from sklearn.neural_network to train our model. We tested different combinations of parameters and we found that the best combination is:\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Hyperparameter tuning methodology:** We used the both HalvingRandomSearchCV and HalvingGridSearchCV to find the best combination of parameters. We began with the HalvingRandomSearchCV and we tested a large spectrum of choices for every hyperparameter. We then used the HalvingGridSearchCV to narrow down the choices for every hyperparameter. In the end, we used the HalvingGridSearchCV to find the best combination of parameters, based on the results we found on our previous tests. In our first two tests, we used the exact same parameters without narrowing them down but we changed the scoring function to from accuracy to f1_micro. We found that the best results occured when we used the f1_micro scoring function, so we used it for the rest of the tests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg7WOYlWnE1h"
      },
      "source": [
        "### **Test results and analysis:**\n",
        "\n",
        "#### **Test 1 HalvingRandomSearchCV with scoring = 'accuracy'**\n",
        "\n",
        "##### **Test parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | [0.0, 0.05, 0.1] |\n",
        "pca__n_components | [0.1, 0.35, 0.75, 0.9] |\n",
        "clf__solver | ['sgd', 'adam'] |\n",
        "clf__activation | ['tanh', 'relu'] |\n",
        "clf__alpha | [0.01, 0.1, 0.5, 1, 2] |\n",
        "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100), (100, 100, 100, 100)] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | 0.0 |\n",
        "pca__n_components | 0.9 |\n",
        "clf__solver | adam |\n",
        "clf__activation | tanh |\n",
        "clf__alpha | 0.1 |\n",
        "clf__hidden_layer_sizes | (100, 100)\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.907917 |\t0.909672 |\n",
        "\n",
        "##### **Comment:** These scores will be used to compare the accuracy and f1 micro scoring functions.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Test 2 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
        "\n",
        "##### **Test parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | [0.0, 0.05, 0.1] |\n",
        "pca__n_components | [0.1, 0.35, 0.75, 0.9] |\n",
        "clf__solver | ['sgd', 'adam'] |\n",
        "clf__activation | ['tanh', 'relu'] |\n",
        "clf__alpha | [0.01, 0.1, 0.5, 1, 2] |\n",
        "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100), (100, 100, 100, 100)] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | 0.0 |\n",
        "pca__n_components | 0.9 |\n",
        "clf__solver | adam |\n",
        "clf__activation | tanh |\n",
        "clf__alpha | 0.1 |\n",
        "clf__hidden_layer_sizes | (100, 100)\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.919538 |\t0.920614 |\n",
        "\n",
        "##### **Comment:** Comparing the scores of test 1 and 2, we came to the conclusion that the f1_micro scoring function produces better results, so we will use it in our next tests. For the next test we will narrow down the values for every hyperparameter to values closer to the optimal value from this test.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Test 3 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
        "\n",
        "\n",
        "##### **Test parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | [0.0, 0.02, 0.5] |\n",
        "pca__n_components | [0.85, 0.9, 0.99] |\n",
        "clf__solver | ['sgd', 'adam'] |\n",
        "clf__activation | ['tanh', 'relu'] |\n",
        "clf__alpha | [0.05, 0.1, 0.15] |\n",
        "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100), (100, 100, 100, 100)] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | 0.0 |\n",
        "pca__n_components | 0.99 |\n",
        "clf__solver | adam |\n",
        "clf__activation | tanh |\n",
        "clf__alpha | 0.05 |\n",
        "clf__hidden_layer_sizes | (100, 100)\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.910096 |\t0.911866 |\n",
        "\n",
        "##### **Comment:** As we can see, the hyperparameters clf__solver and clf__activation always work better with the values 'adam' and 'tanh'. These will be our final values for those hyperparameters and we will stop testing for them. We also see the same pattern for clf__hidden_layer_sizes, we will continue testing but only choices closer to the (100, 100) choice.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Test 4 GridSearchCV with scoring = 'f1_micro'**\n",
        "\n",
        "\n",
        "##### **Test parameters:**\n",
        "\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | [0.0, 0.01] |\n",
        "pca__n_components | [0.98, 0.99] |\n",
        "clf__alpha | [0.02, 0.05, 0.07] |\n",
        "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100)] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "selector__threshold | 0.0 |\n",
        "pca__n_components | 0.99 |\n",
        "clf__alpha | 0.07 |\n",
        "clf__hidden_layer_sizes | (100, 100)\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.912194 |\t0.913875 |\n",
        "\n",
        "##### **Comment:** Since the hyperparameter values were almost completely optimized, we used GridSearchCV for our last test, because training time was not a problem (few combinations needed to be tested). The final testing score was marginally better than the previous versions.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "sr0olIVsnE1h",
        "outputId": "a945d97f-45bc-475f-ea05-55c8b1f22b56"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "# from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "\n",
        "\n",
        "# Initialize the transformers without hyperparameters\n",
        "selector = VarianceThreshold()\n",
        "scaler = MinMaxScaler()\n",
        "rus = RandomUnderSampler()\n",
        "pca = PCA()\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe_mlp = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', pca), ('clf', MLPClassifier(solver=\"adam\", activation=\"tanh\"))], memory = 'tmp')\n",
        "\n",
        "# Define the hyperparameters\n",
        "param_grid_mlp = {\n",
        "    'selector__threshold': [0.0, 0.01],\n",
        "    'pca__n_components': [0.98, 0.99],\n",
        "    'clf__alpha': [0.02, 0.05, 0.07],\n",
        "    'clf__hidden_layer_sizes': [(100, 100), (100, 100, 100)]\n",
        "} \n",
        "\n",
        "# Initialize the HalvingRandomSearchCV search\n",
        "grid_mlp = GridSearchCV(pipe_mlp, param_grid_mlp, cv=10, n_jobs=-1, verbose=1, scoring='f1_micro')\n",
        "\n",
        "# Fit the grid search\n",
        "grid_mlp.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Isz_hb7ynE1i",
        "outputId": "1bf00bcc-d026-4d59-f60c-8a56dd9eee03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9106945506946008\n",
            "{'clf__alpha': 0.07, 'clf__hidden_layer_sizes': (100, 100), 'pca__n_components': 0.99, 'selector__threshold': 0.0}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "|          |   Accuracy |   F1 Score |\n",
              "|:---------|-----------:|-----------:|\n",
              "| Pipeline |   0.912194 |   0.913875 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATuElEQVR4nO3de5CV9Zng8e9Do0LASwRMJTbQvTNKQXERC8RrMKVG3VUQmTK4Lq5ZI6RSorsz2YrW7qqY/WNiEnOpOBYm3qIbvKVA4riRIKaM6yqXLDWIxIV12wViIoMZtEHk9uwf58C02NCn4eBJ//h+qijP+563z3maKr+8/etz3hOZiSSp5+vV6AEkSfVh0CWpEAZdkgph0CWpEAZdkgph0CWpEL0b9cQDBw7MlpaWRj29JPVIy5cv/8fMHNTZfQ0LektLC8uWLWvU00tSjxQRb+3vPpdcJKkQBl2SCmHQJakQDVtDl1SuHTt2sH79erZt29boUXqsPn360NzczFFHHVXz1xh0SXW3fv16jj32WFpaWoiIRo/T42QmmzZtYv369bS2ttb8dS65SKq7bdu2MWDAAGN+kCKCAQMGdPsnHIMu6bAw5ofmYP7+DLqkYs2fP5+I4He/+12jR/lEuIYu7euO4xs9Qc938RPw++pywefG0nLL39f14dv+9l/VdNzcuXM599xzmTt3LrNnz67rDHvs2rWLpqamw/LY3WXQC1Hv/2GOZG19Gj2B6qG9vZ2XXnqJF154gcsvv5zZs2eza9cuvvGNb/DLX/6SXr16ccMNNzBr1iyWLl3KzTffzJYtWzjmmGN4/vnn+fnPf86yZcv40Y9+BMBll13G17/+dc4//3z69+/PzJkzWbRoEffccw+LFy/mF7/4BR988AFnn302c+bMISJYu3YtX/3qV9m4cSNNTU08+eSTzJ49myuvvJIrrrgCgGuuuYarrrqKyZMnH/L3bNAlFenpp5/mkksu4dRTT2XAgAEsX76cJUuW0NbWxooVK+jduzfvvvsu27dv50tf+hKPP/4448eP57333qNv374HfOwtW7YwYcIEvvvd7wIwYsQIbrvtNgCmT5/OM888w+WXX84111zDLbfcwpQpU9i2bRu7d+/m+uuv53vf+x5XXHEFmzdv5uWXX+bhhx+uy/fsGrqkIs2dO5dp06YBMG3aNObOncuiRYuYOXMmvXtXzmVPPPFE3njjDT772c8yfvx4AI477ri99+9PU1MTU6dO3bv9wgsvMGHCBEaNGsXixYtZtWoV77//Phs2bGDKlClA5XXln/rUp5g4cSJr1qxh48aNzJ07l6lTp3b5fLXyDF1Scd59910WL17MypUriQh27dpFROyNdi169+7N7t279253fAlhnz599q6bb9u2ja997WssW7aMwYMHc8cdd3T5csNrr72WRx99lMcee4wHH3ywm9/d/nmGLqk4Tz31FNOnT+ett96ira2NdevW0draypgxY5gzZw47d+4EKuEfNmwYb7/9NkuXLgXg/fffZ+fOnbS0tLBixQp2797NunXrWLJkSafPtSfeAwcOpL29naeeegqAY489lubmZubPnw/Ahx9+yNatWwG47rrr+P73vw9UlmvqxaBLKs7cuXP3LnXsMXXqVN5++22GDBnC6NGjGTNmDD/72c84+uijefzxx5k1axZjxozhoosuYtu2bZxzzjm0trYyYsQIbrrpJk4//fROn+uEE07ghhtuYOTIkVx88cUf+SngkUce4Yc//CGjR4/m7LPP5g9/+AMAn/nMZxg+fDhf/vKX6/p9R2bW9QFrNW7cuPR66PXjq1zqp63Pv270CD3e6oufYPjQkyobnxvb2GH+DG3dupVRo0bx29/+luOP3//LZFevXs3w4cM/si8ilmfmuM6O9wxdkj5BixYtYvjw4cyaNeuAMT8Y/lJUkj5BF154IW+9td8PHToknqFLUiEMuiQVwqBLUiEMuiQVwqBLKlJTUxOnnXba3j9tbW1s2rSJL3zhC/Tv358bb7xxv1/7zDPPMHbsWMaMGcOIESOYM2fOJzj5wfNVLpIOv3pfkviOzV0e0rdvX1asWPGRfVu2bOGb3/wmr732Gq+99lqnX7djxw5mzJjBkiVLaG5u5sMPP6Stre2Qxs1MMpNevQ7vObRn6JKOGP369ePcc8+lT5/9XyN5z1v/BwwYAMAxxxzDsGHDAPjjH//IlClTGDNmDGPGjOHll18G4O6772bkyJGMHDly71v629raGDZsGNdeey0jR45k3bp1fPvb32b8+PGMHj2a22+/ve7fn2fokor0wQcfcNpppwHQ2trKvHnzavq6E088kUmTJjF06FAuuOACLrvsMq6++mp69erFTTfdxMSJE5k3bx67du2ivb2d5cuX8+CDD/Lqq6+SmUyYMIGJEyfy6U9/mjVr1vDwww9z5plnsnDhQtasWcOSJUvITCZNmsSLL77I5z//+bp9zwZdUpE6W3Kp1U9+8hNWrlzJokWL+M53vsOvfvUrHnroIRYvXsxPf/pToLJGf/zxx/PSSy8xZcoU+vXrB8CVV17Jb37zm73/KJx55pkALFy4kIULFzJ2bOVSCO3t7axZs8agS9LhNmrUKEaNGsX06dNpbW3loYce6vZj7Ik8VNbRb731VmbOnFnHKT/KNXRJ6qC9vZ1f//rXe7dXrFjB0KFDAbjgggu49957gcpniW7evJnzzjuP+fPns3XrVrZs2cK8efM477zzPva4F198MQ888ADt7e0AbNiwgXfeeaeus3uGLumI0tLSwnvvvcf27duZP38+Cxcu/Mg1yTOTu+66i5kzZ9K3b1/69eu39+z8Bz/4ATNmzOD++++nqamJe++9l7POOovrrruOM844A4CvfOUrjB079mOvjPniF7/I6tWrOeusswDo378/jz76KCeddFLdvreaLp8bEZcAPwCagJ9k5t/uc/8Q4GHghOoxt2Tmswd6TC+fW19ePrd+vHzuofPyufVR98vnRkQTcA9wKTACuDoi9v2Ijf8MPJGZY4FpwN8dxOySpENQyxr6GcDazHwzM7cDjwGT9zkmgeOqt48Hfl+/ESVJtahlDf1kYF2H7fXAhH2OuQNYGBGzgH7AhXWZTpJUs3q9yuVq4KHMbAb+JfBIRHzssSNiRkQsi4hlGzdurNNTS/rzU3mruw7ewfz91RL0DcDgDtvN1X0dXQ88UR3ifwJ9gIGdDHhfZo7LzHGDBg3q9rCSeoY+m99k05adRv0gZSabNm064CUKOlPLkstS4JSIaKUS8mnAvi8D+H/ABcBDETGcStA9BZeOUM2//Rbr+QYbj/8X8N7qRo/TI/Xp04fm5uZufU2XQc/MnRFxI/AclZckPpCZqyLiTmBZZi4A/gb4cUT8Byq/IL0u/adZOmIdtf2faH3l1spGDVdGVH3U9Mai6mvKn91n320dbr8OnFPf0SRJ3eFb/yWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEAZdkgph0CWpEDUFPSIuiYg3ImJtRNyyn2OuiojXI2JVRPysvmNKkrrSu6sDIqIJuAe4CFgPLI2IBZn5eodjTgFuBc7JzD9FxEmHa2BJUudqOUM/A1ibmW9m5nbgMWDyPsfcANyTmX8CyMx36jumJKkrtQT9ZGBdh+311X0dnQqcGhH/IyJeiYhL6jWgJKk2XS65dONxTgHOB5qBFyNiVGb+U8eDImIGMANgyJAhdXpqSRLUdoa+ARjcYbu5uq+j9cCCzNyRmf8X+N9UAv8RmXlfZo7LzHGDBg062JklSZ2oJehLgVMiojUijgamAQv2OWY+lbNzImIglSWYN+s4pySpC10GPTN3AjcCzwGrgScyc1VE3BkRk6qHPQdsiojXgReA/5iZmw7X0JKkj6tpDT0znwWe3WffbR1uJ/DX1T+SpAbwnaKSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFMOiSVAiDLkmFqCnoEXFJRLwREWsj4pYDHDc1IjIixtVvRElSLboMekQ0AfcAlwIjgKsjYkQnxx0L3Ay8Wu8hJUldq+UM/QxgbWa+mZnbgceAyZ0c903gW8C2Os4nSapRLUE/GVjXYXt9dd9eEXE6MDgz/76Os0mSuuGQfykaEb2Au4G/qeHYGRGxLCKWbdy48VCfWpLUQS1B3wAM7rDdXN23x7HASODXEdEGnAks6OwXo5l5X2aOy8xxgwYNOvipJUkfU0vQlwKnRERrRBwNTAMW7LkzMzdn5sDMbMnMFuAVYFJmLjssE0uSOtVl0DNzJ3Aj8BywGngiM1dFxJ0RMelwDyhJqk3vWg7KzGeBZ/fZd9t+jj3/0MeSJHWX7xSVpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqhEGXpEIYdEkqRE1Bj4hLIuKNiFgbEbd0cv9fR8TrEfEPEfF8RAyt/6iSpAPpMugR0QTcA1wKjACujogR+xz2v4BxmTkaeAq4q96DSpIOrJYz9DOAtZn5ZmZuBx4DJnc8IDNfyMyt1c1XgOb6jilJ6kotQT8ZWNdhe3113/5cD/z3QxlKktR9vev5YBHxb4BxwMT93D8DmAEwZMiQej61JB3xajlD3wAM7rDdXN33ERFxIfCfgEmZ+WFnD5SZ92XmuMwcN2jQoIOZV5K0H7UEfSlwSkS0RsTRwDRgQccDImIsMIdKzN+p/5iSpK50GfTM3AncCDwHrAaeyMxVEXFnREyqHvZtoD/wZESsiIgF+3k4SdJhUtMaemY+Czy7z77bOty+sM5zSZK6yXeKSlIhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1Ihagp6RFwSEW9ExNqIuKWT+4+JiMer978aES31HlSSdGBdBj0imoB7gEuBEcDVETFin8OuB/6UmX8JfA/4Vr0HlSQdWC1n6GcAazPzzczcDjwGTN7nmMnAw9XbTwEXRETUb0xJUldqCfrJwLoO2+ur+zo9JjN3ApuBAfUYUJJUm96f5JNFxAxgRnWzPSLe+CSfX6pFwEDgHxs9RzFm+8N6nQ3d3x21BH0DMLjDdnN1X2fHrI+I3sDxwKZ9Hygz7wPuq+E5pYaJiGWZOa7Rc0jdVcuSy1LglIhojYijgWnAgn2OWQD82+rtvwIWZ2bWb0xJUle6PEPPzJ0RcSPwHNAEPJCZqyLiTmBZZi4A7gceiYi1wLtUoi9J+gSFJ9LSR0XEjOryoNSjGHRJKoRv/ZekQhh0SSqEQZekQhh0CYiIT0XEf4mIH1e3T4mIyxo9l9QdBl2qeBD4EDirur0B+K+NG0fqPoMuVfxFZt4F7ADIzK2A71lXj2LQpYrtEdEXSICI+AsqZ+xSj/GJXpxL+jN2O/BLYHBE/DfgHOC6hk4kdZNvLJKqImIAcCaVpZZXMtMrLqpHMehSVUScTOXSpHt/cs3MFxs3kdQ9LrlIQER8C/gSsArYXd2dgEFXj+EZugRUP2xldGb6i1D1WL7KRap4Eziq0UNIh8IlF6liK7AiIp6nw8sVM/Omxo0kdY9BlyoW8PFP4pJ6FNfQJakQnqHriBYRT2TmVRGxkuq7RDvKzNENGEs6KJ6h64gWEZ/NzLcjYmhn92fmW5/0TNLBMuiSVAiXXHREi4j3+eellj1XV8zq7czM4xoymHQQPEOXpEL4xiKpKiLOjYgvV28PjIjWRs8kdYdn6BIQEbcD44BhmXlqRHwOeDIzz2nwaFLNPEOXKqYAk4AtAJn5e+DYhk4kdZNBlyq2Z+XH1T2fWNSvwfNI3WbQpYonImIOcEJE3AAsAn7c4JmkbnENXaqKiIuAL1Y3F2bmrxo5j9Rdvg5d+mcrgT0fFL2ywbNI3eaSiwRExFeAJcCVwF8Br0TEv2vsVFL3uOQisfcTi87OzE3V7QHAy5k5rLGTSbXzDF2q2AS832H7/eo+qcfwDF0CIuKnwCjgaSpr6JOBf6j+ITPvbtx0Um38pahU8X+qf/Z4uvpf31ykHsMzdEkqhGfoOqJFxPcz899HxC/o/BOLJjVgLOmgGHQd6R6p/vc7DZ1CqgOXXHREi4g+wFeBv6TyZqL7M3NnY6eSDo5B1xEtIh4HdgC/AS4F3srMmxs7lXRwDLqOaBGxMjNHVW/3BpZk5ukNHks6KL6xSEe6HXtuuNSins4zdB3RImIX1Q+1oPLB0H2Brfgh0eqBDLokFcIlF0kqhEGXpEIYdEkqhEGXpEIYdEkqxP8HFfFmBjEdWxAAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
        "grid_mlp_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
        "y_pred = grid_mlp.best_estimator_.predict(X_test)\n",
        "grid_mlp_df.loc[grid_mlp.best_estimator_.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
        "\n",
        "\n",
        "print(grid_mlp.best_score_)\n",
        "print(grid_mlp.best_params_)\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "\n",
        "# display the results of the classifiers in a comparison bar plot\n",
        "comparisonBarPlot = grid_mlp_df.plot.bar()\n",
        "\n",
        "# display the results of the classifiers in a markdown table\n",
        "markDownTableResults = grid_mlp_df.to_markdown()\n",
        "md(markDownTableResults)# # # # # # # # # # # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ShfS4lIqnE1i",
        "outputId": "9535f9b4-2ca9-4f38-8321-76e28f982de2"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.under_sampling import RandomUnderSampler \n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# -- Define the objective function\n",
        "def objective(trial):\n",
        "\n",
        "    # -- Instantiate selector\n",
        "    selector_threshold = trial.suggest_float('selector__threshold', 0.0, 0.1)\n",
        "\n",
        "    selector = VarianceThreshold(threshold=selector_threshold)\n",
        "\n",
        "    # -- Instantiate UnderSampler\n",
        "    rus = RandomUnderSampler()\n",
        "\n",
        "    # -- Instantiate scaler\n",
        "    # (a) List scalers to chose from\n",
        "    scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard'])\n",
        "\n",
        "    # (b) Define your scalers\n",
        "    if scalers == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "    elif scalers == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "    # -- Instantiate dimensionality reduction\n",
        "     # (a) List all dimensionality reduction options\n",
        "    dim_red = trial.suggest_categorical(\"dim_red\", [\"PCA\", None])\n",
        "\n",
        "    # (b) Define the PCA algorithm and its hyperparameters\n",
        "    if dim_red == \"PCA\":\n",
        "        pca_n_components=trial.suggest_int(\"pca_n_components\", 50, 171)\n",
        "        dimen_red_algorithm=PCA(n_components=pca_n_components)\n",
        "    # (c) No dimensionality reduction option\n",
        "    else:\n",
        "        dimen_red_algorithm='passthrough'\n",
        "\n",
        "    # -- Instantiate estimator model\n",
        "    alpha=trial.suggest_float('clf__alpha', 0.01, 2.0)\n",
        "    solver=trial.suggest_categorical('clf__solver', ['adam', 'sgd'])\n",
        "    activation=trial.suggest_categorical('clf__activation', ['relu', 'tanh'])\n",
        "\n",
        "    estimator = MLPClassifier(alpha=alpha, solver=solver, activation=activation)\n",
        "\n",
        "    ##########\n",
        "\n",
        "\n",
        "    # -- Make a pipeline\n",
        "    pipeline = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', dimen_red_algorithm), ('clf', estimator)], memory = 'tmp')\n",
        "\n",
        "    # -- Evaluate the score by cross-validation\n",
        "    score = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=5)\n",
        "    acc = score.mean() # calculate the mean of scores\n",
        "    return acc\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\") # maximise the score during tuning\n",
        "study.optimize(objective, n_trials=20) # run the objective function 20 times\n",
        "\n",
        "print(study.best_trial) # print the best performing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "y7RUUhkG4PKk",
        "outputId": "dd58737c-9698-464e-dd0a-76d439e4d38f"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "|          |   Accuracy |   F1 Score |\n",
              "|:---------|-----------:|-----------:|\n",
              "| Pipeline |    0.92656 |   0.927677 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Initialize the transformers without hyperparameters\n",
        "selector = VarianceThreshold(threshold=0.0024547727859665306)\n",
        "scaler = StandardScaler()\n",
        "rus = RandomUnderSampler()\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe_mlp_optuna = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus),  ('clf', MLPClassifier(alpha=1.8745876376736077,solver=\"sgd\", activation=\"relu\"))], memory = 'tmp')\n",
        "\n",
        "\n",
        "# Fit the grid search\n",
        "pipe_mlp_optuna.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
        "pipe_mlp_optuna_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
        "y_pred = pipe_mlp_optuna.predict(X_test)\n",
        "pipe_mlp_optuna_df.loc[pipe_mlp_optuna.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "\n",
        "# display the results of the classifiers in a comparison bar plot\n",
        "comparisonBarPlot = pipe_mlp_optuna_df.plot.bar()\n",
        "\n",
        "# display the results of the classifiers in a markdown table\n",
        "markDownTableResults = pipe_mlp_optuna_df.to_markdown()\n",
        "md(markDownTableResults)# # # # # # # # # # # \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkkK2h4ewdI8"
      },
      "source": [
        "### **Conclusion for MLP:**\n",
        "\n",
        "Results |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Out of the box |\t0.913566  |\t0.903664 |\n",
        "Hyperparameter Optimization |\t0.912194 | 0.913875 |\n",
        "Optuna |\t0.924784 |  0.925889 |\n",
        "\n",
        "As we can see, we achieved minor increases in performance by using hyperparameter optimization. The Optuna hyperparameter optimization was the most effective, easier to set up and faster to run. Mainly based on the performance results, we will consider this as the best MLP estimator for our final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkfrlS7T1Iph"
      },
      "source": [
        "### **SVM Classifier training**\n",
        "\n",
        "#### **Data preprocessing:** We tested a combination of data preprocessing techniques, including:\n",
        "\n",
        "- **Standardization:** We used the MinMaxScaler for standarisizing the data. We did not use the StandardScaler because it is sensitive to outliers.\n",
        "\n",
        "- **Feature selection:** We used the VarianceThreshold to remove features with low variance.\n",
        "\n",
        "- **Sampling:** We used the RandomUnderSampler to undersample the majority of the classes. We avoided using the oversampling techniques because we had a large volume of data and we wanted to avoid overfitting and large training times.\n",
        "\n",
        "- **Feature extraction:** We found that PCA does not make a differenence so we removed it.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "#### **SVC Classifier:** We used the SVC Classifier from sklearn.neural_network to train our model. We tested different combinations of parameters and we found the best combination.\n",
        "\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Hyperparameter tuning methodology:** We used HalvingRandomSearchCV to find the best combination of parameters. In our first two tests, we used the exact same parameters without narrowing them down but we changed the scoring function from accuracy to f1_micro. We found that both scoring functions had similar results, so we used f1_micro for the rest of the tests.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHlKj9pEc77T"
      },
      "source": [
        "### **Test results and analysis SVM:**\n",
        "\n",
        "#### **Test 1 HalvingRandomSearchCV with scoring = 'accuracy'**\n",
        "\n",
        "##### **Test parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | [0.1, 1, 10, 100, 1000] |\n",
        "clf__gamma | [1, 0.1, 0.01, 0.001, 0.0001] |\n",
        "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | 10 |\n",
        "clf__gamma | 0.01 |\n",
        "clf__kernel | linear |\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.930918 |\t0.931034 |\n",
        "\n",
        "##### **Comment:** These scores will be used to compare the accuracy and f1 micro scoring functions.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Test 2 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
        "\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | [0.1, 1, 10, 100, 1000] |\n",
        "clf__gamma | [1, 0.1, 0.01, 0.001, 0.0001] |\n",
        "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | 100 |\n",
        "clf__gamma | 1 |\n",
        "clf__kernel | linear |\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.930998 |\t0.931106 |\n",
        "\n",
        "##### **Comment:** Comparing the scores of test 1 and 2, we came to the conclusion that both the f1_micro and accuracy scoring functions produce similar results. We choose to use the f1_micro in our next tests. For the next test we will narrow down the values for every hyperparameter to values closer to the optimal value from this test.\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### **Test 3 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
        "\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | [50, 100, 500] |\n",
        "clf__gamma | [1.1, 1, 0.9] |\n",
        "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | 50 |\n",
        "clf__gamma | 1 |\n",
        "clf__kernel | linear |\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.930756 |\t0.930947 |\n",
        "\n",
        "##### **Comment:** The linear clf kernel performs always better and that's why we we pick it as the classifier kernel. The optimal value of the C parameter seems to be around 50, so we limit the range of values around 50. We keep gamma parameter equal to 1.\n",
        "\n",
        "#### **Test 4 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
        "\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | [25, 50, 75] |\n",
        "clf__gamma | [1] |\n",
        "clf__kernel | ['linear'] |\n",
        "\n",
        "##### **Best parameters:**\n",
        "\n",
        "Hyperparameter | Values |\n",
        "----------- | ----------- |\n",
        "clf__C | 75 |\n",
        "clf__gamma | 1 |\n",
        "clf__kernel | linear |\n",
        "\n",
        "\n",
        "##### **Test score:**\n",
        "Scores |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Pipeline |\t0.930756 |\t0.930947 |\n",
        "\n",
        "##### **Comment:** What we see here is that parameter C should have the value of 75. We also notice that Scoring values don't change. This observation, together with previous observations, leads us to conclude that the parameter C does not affect scoring values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v499vz4EdGfV",
        "outputId": "315f8188-0e54-4293-c525-5a7b268a07e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_iterations: 2\n",
            "n_required_iterations: 2\n",
            "n_possible_iterations: 6\n",
            "min_resources_: 80\n",
            "max_resources_: 28912\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 3\n",
            "n_resources: 80\n",
            "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 1\n",
            "n_resources: 240\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "HalvingRandomSearchCV(cv=10,\n",
              "                      estimator=Pipeline(memory='tmp',\n",
              "                                         steps=[('selector',\n",
              "                                                 VarianceThreshold()),\n",
              "                                                ('scaler', MinMaxScaler()),\n",
              "                                                ('rus', RandomUnderSampler()),\n",
              "                                                ('pca', PCA()),\n",
              "                                                ('clf', SVC())]),\n",
              "                      n_jobs=-1,\n",
              "                      param_distributions={'clf__C': [25, 50, 75],\n",
              "                                           'clf__gamma': [1],\n",
              "                                           'clf__kernel': ['linear']},\n",
              "                      scoring='f1_micro', verbose=1)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "\n",
        "\n",
        "# Initialize the transformers without hyperparameters\n",
        "selector = VarianceThreshold()\n",
        "scaler = MinMaxScaler()\n",
        "rus = RandomUnderSampler()\n",
        "pca = PCA()\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe_svc = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', pca), ('clf', SVC())], memory = 'tmp')\n",
        "\n",
        "# Define the hyperparameters\n",
        "param_grid_svc = {\n",
        "              'clf__C': [25, 50, 75], \n",
        "              'clf__gamma': [1],\n",
        "              'clf__kernel': ['linear']} \n",
        "\n",
        "\n",
        "grid_svc = HalvingRandomSearchCV(pipe_svc, param_grid_svc, cv=10, n_jobs=-1, verbose=1, scoring='f1_micro')\n",
        "\n",
        "# Fit the grid search\n",
        "grid_svc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "bHz2LXaYdTxX",
        "outputId": "cec93067-1409-4f19-c569-79d3339a026d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7208333333333333\n",
            "{'clf__kernel': 'linear', 'clf__gamma': 1, 'clf__C': 75}\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "|          |   Accuracy |   F1 Score |\n",
              "|:---------|-----------:|-----------:|\n",
              "| Pipeline |   0.930756 |   0.930947 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATtElEQVR4nO3de5CV9Zng8e9Do0JATQRMJTbQvTNKQXERC8VrMKVGnVUQmTI4Lq5ZI6RSolsz2YrW7qqY/WNjEnOpuBZOjBrdtLeUSBwnEoSUcV3lkmGDSFxYt10gJjKYQRtEbs/+cQ5Mi419Gg6c6R/fTxXFed/z9jlPU+XXt399znsiM5Ek9X59Gj2AJKk+DLokFcKgS1IhDLokFcKgS1IhDLokFaJvo5548ODB2dLS0qinl6Reafny5f+YmUO6uq9hQW9paWHZsmWNenpJ6pUi4s393eeSiyQVwqBLUiEMuiQVomFr6JLKtWPHDtavX8+2bdsaPUqv1a9fP5qbmznqqKNq/hqDLqnu1q9fz7HHHktLSwsR0ehxep3MZNOmTaxfv57W1taav84lF0l1t23bNgYNGmTMD1BEMGjQoB7/hGPQJR0SxvzgHMi/n0GXVKx58+YREfzud79r9CiHhWvo0r7uOL7RE/R+Fz8Ov68uF3x2PC23/F1dH779v/7rmo5ra2vj3HPPpa2tjTlz5tR1hj127dpFU1PTIXnsnjLohaj3fzBHsvZ+jZ5A9dDR0cGLL77I4sWLufzyy5kzZw67du3i61//Or/4xS/o06cPN9xwA7Nnz2bp0qXcfPPNbNmyhWOOOYbnn3+en/3sZyxbtowf/vCHAFx22WV87Wtf4/zzz2fgwIHMmjWLhQsXcs8997Bo0SJ+/vOf8/7773P22Wczd+5cIoK1a9fyla98hY0bN9LU1MQTTzzBnDlzuPLKK7niiisAuOaaa7jqqquYMmXKQX/PBl1SkZ5++mkuueQSTjnlFAYNGsTy5ctZsmQJ7e3trFixgr59+/LOO++wfft2vvjFL/LYY49x+umn8+6779K/f/+PfewtW7YwceJEvvOd7wAwatQobrvtNgBmzJjBM888w+WXX84111zDLbfcwtSpU9m2bRu7d+/m+uuv57vf/S5XXHEFmzdv5qWXXuKhhx6qy/fsGrqkIrW1tTF9+nQApk+fTltbGwsXLmTWrFn07Vs5lz3hhBN4/fXX+cxnPsPpp58OwHHHHbf3/v1pampi2rRpe7cXL17MxIkTGTNmDIsWLWLVqlW89957bNiwgalTpwKV15V/4hOfYNKkSaxZs4aNGzfS1tbGtGnTun2+WnmGLqk477zzDosWLWLlypVEBLt27SIi9ka7Fn379mX37t17tzu/hLBfv3571823bdvGV7/6VZYtW8bQoUO54447un254bXXXssjjzzCo48+ygMPPNDD727/PEOXVJwnn3ySGTNm8Oabb9Le3s66detobW1l3LhxzJ07l507dwKV8I8YMYK33nqLpUuXAvDee++xc+dOWlpaWLFiBbt372bdunUsWbKky+faE+/BgwfT0dHBk08+CcCxxx5Lc3Mz8+bNA+CDDz5g69atAFx33XV873vfAyrLNfVi0CUVp62tbe9Sxx7Tpk3jrbfeYtiwYYwdO5Zx48bx05/+lKOPPprHHnuM2bNnM27cOC666CK2bdvGOeecQ2trK6NGjeKmm27itNNO6/K5PvnJT3LDDTcwevRoLr744g/9FPDwww/zgx/8gLFjx3L22Wfzhz/8AYBPf/rTjBw5ki996Ut1/b4jM+v6gLWaMGFCej30+vFVLvXT3u+vGj1Cr7f64scZOfzEysZnxzd2mH+Btm7dypgxY/jNb37D8cfv/2Wyq1evZuTIkR/aFxHLM3NCV8d7hi5Jh9HChQsZOXIks2fP/tiYHwh/KSpJh9GFF17Im2/u90OHDopn6JJUCIMuSYUw6JJUCIMuSYUw6JKK1NTUxKmnnrr3T3t7O5s2beLzn/88AwcO5MYbb9zv1z7zzDOMHz+ecePGMWrUKObOnXsYJz9wvspF0qFX70sS37G520P69+/PihUrPrRvy5YtfOMb3+DVV1/l1Vdf7fLrduzYwcyZM1myZAnNzc188MEHtLe3H9S4mUlm0qfPoT2H9gxd0hFjwIABnHvuufTrt/9rJO956/+gQYMAOOaYYxgxYgQAf/zjH5k6dSrjxo1j3LhxvPTSSwDcfffdjB49mtGjR+99S397ezsjRozg2muvZfTo0axbt45vfetbnH766YwdO5bbb7+97t+fZ+iSivT+++9z6qmnAtDa2spTTz1V09edcMIJTJ48meHDh3PBBRdw2WWXcfXVV9OnTx9uuukmJk2axFNPPcWuXbvo6Ohg+fLlPPDAA7zyyitkJhMnTmTSpEl86lOfYs2aNTz00EOceeaZLFiwgDVr1rBkyRIyk8mTJ/PCCy/wuc99rm7fs0GXVKSullxq9aMf/YiVK1eycOFCvv3tb/PLX/6SBx98kEWLFvGTn/wEqKzRH3/88bz44otMnTqVAQMGAHDllVfy61//eu//FM4880wAFixYwIIFCxg/vnIphI6ODtasWWPQJelQGzNmDGPGjGHGjBm0trby4IMP9vgx9kQeKuvot956K7NmzarjlB/mGrokddLR0cGvfvWrvdsrVqxg+PDhAFxwwQXce++9QOWzRDdv3sx5553HvHnz2Lp1K1u2bOGpp57ivPPO+8jjXnzxxfz4xz+mo6MDgA0bNvD222/XdXbP0CUdUVpaWnj33XfZvn078+bNY8GCBR+6JnlmctdddzFr1iz69+/PgAED9p6df//732fmzJncf//9NDU1ce+993LWWWdx3XXXccYZZwDw5S9/mfHjx3/klTFf+MIXWL16NWeddRYAAwcO5JFHHuHEE0+s2/fm5XML4eVz68fL5x48L59bH14+V5KOUAZdkgph0CWpEDUFPSIuiYjXI2JtRNzSxf3DImJxRPxDRPw2Iv6i/qNK6j0qb3XXgTuQf79ugx4RTcA9wKXAKODqiNj3Y6r/E/B4Zo4HpgP/rceTSCpGv81vsGnLTqN+gDKTTZs2fewlCrpSy8sWzwDWZuYbABHxKDAFeK3z8wPHVW8fD/y+R1NIKkrzb77Jer7OxuP/Fby7utHj9Er9+vWjubm5R19TS9BPAtZ12l4PTNznmDuABRExGxgAXNijKSQV5ajt/0Try7dWNmq4MqLqo16/FL0aeDAzm4G/AB6OiI88dkTMjIhlEbFs48aNdXpqSRLUFvQNwNBO283VfZ1dDzwOkJn/E+gHDN73gTLzvsyckJkThgwZcmATS5K6VEvQlwInR0RrRBxN5Zee8/c55v8BFwBExEgqQfcUXJIOo26Dnpk7gRuB54DVVF7Nsioi7oyIydXD/ga4ISL+F9AGXJf+eluSDquaLs6Vmc8Cz+6z77ZOt18DzqnvaJKknvCdopJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUCIMuSYUw6JJUiJqCHhGXRMTrEbE2Im7ZzzFXRcRrEbEqIn5a3zElSd3p290BEdEE3ANcBKwHlkbE/Mx8rdMxJwO3Audk5p8i4sRDNbAkqWu1nKGfAazNzDcyczvwKDBln2NuAO7JzD8BZObb9R1TktSdWoJ+ErCu0/b66r7OTgFOiYj/EREvR8Ql9RpQklSbbpdcevA4JwPnA83ACxExJjP/qfNBETETmAkwbNiwOj21JAlqO0PfAAzttN1c3dfZemB+Zu7IzP8L/G8qgf+QzLwvMydk5oQhQ4Yc6MySpC7UEvSlwMkR0RoRRwPTgfn7HDOPytk5ETGYyhLMG3WcU5LUjW6Dnpk7gRuB54DVwOOZuSoi7oyIydXDngM2RcRrwGLgP2TmpkM1tCTpo2paQ8/MZ4Fn99l3W6fbCfx19Y8kqQF8p6gkFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1IhDLokFcKgS1Ihagp6RFwSEa9HxNqIuOVjjpsWERkRE+o3oiSpFt0GPSKagHuAS4FRwNURMaqL444FbgZeqfeQkqTu1XKGfgawNjPfyMztwKPAlC6O+wbwTWBbHeeTJNWolqCfBKzrtL2+um+viDgNGJqZf1fH2SRJPXDQvxSNiD7A3cDf1HDszIhYFhHLNm7ceLBPLUnqpJagbwCGdtpuru7b41hgNPCriGgHzgTmd/WL0cy8LzMnZOaEIUOGHPjUkqSPqCXoS4GTI6I1Io4GpgPz99yZmZszc3BmtmRmC/AyMDkzlx2SiSVJXeo26Jm5E7gReA5YDTyemasi4s6ImHyoB5Qk1aZvLQdl5rPAs/vsu20/x55/8GNJknrKd4pKUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiEMuiQVwqBLUiFqCnpEXBIRr0fE2oi4pYv7/zoiXouI30bE8xExvP6jSpI+TrdBj4gm4B7gUmAUcHVEjNrnsH8AJmTmWOBJ4K56DypJ+ni1nKGfAazNzDcyczvwKDCl8wGZuTgzt1Y3Xwaa6zumJKk7tQT9JGBdp+311X37cz3w9wczlCSp5/rW88Ei4t8AE4BJ+7l/JjATYNiwYfV8akk64tVyhr4BGNppu7m670Mi4kLgPwKTM/ODrh4oM+/LzAmZOWHIkCEHMq8kaT9qCfpS4OSIaI2Io4HpwPzOB0TEeGAulZi/Xf8xJUnd6TbombkTuBF4DlgNPJ6ZqyLizoiYXD3sW8BA4ImIWBER8/fzcJKkQ6SmNfTMfBZ4dp99t3W6fWGd55Ik9ZDvFJWkQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSqEQZekQhh0SSpETUGPiEsi4vWIWBsRt3Rx/zER8Vj1/lcioqXeg0qSPl63QY+IJuAe4FJgFHB1RIza57DrgT9l5p8D3wW+We9BJUkfr5Yz9DOAtZn5RmZuBx4FpuxzzBTgoertJ4ELIiLqN6YkqTu1BP0kYF2n7fXVfV0ek5k7gc3AoHoMKEmqTd/D+WQRMROYWd3siIjXD+fzS7UIGAz8Y6PnKMYcf1ivs+H7u6OWoG8Ahnbabq7u6+qY9RHRFzge2LTvA2XmfcB9NTyn1DARsSwzJzR6DqmnallyWQqcHBGtEXE0MB2Yv88x84F/W739l8CizMz6jSlJ6k63Z+iZuTMibgSeA5qAH2fmqoi4E1iWmfOB+4GHI2It8A6V6EuSDqPwRFr6sIiYWV0elHoVgy5JhfCt/5JUCIMuSYUw6JJUCIMuARHxiYj4zxHxt9XtkyPiskbPJfWEQZcqHgA+AM6qbm8A/kvjxpF6zqBLFX+WmXcBOwAycyvge9bVqxh0qWJ7RPQHEiAi/ozKGbvUaxzWi3NJ/4LdDvwCGBoR/x04B7iuoRNJPeQbi6SqiBgEnEllqeXlzPSKi+pVDLpUFREnUbk06d6fXDPzhcZNJPWMSy4SEBHfBL4IrAJ2V3cnYNDVa3iGLgHVD1sZm5n+IlS9lq9ykSreAI5q9BDSwXDJRarYCqyIiOfp9HLFzLypcSNJPWPQpYr5fPSTuKRexTV0SSqEZ+g6okXE45l5VUSspPou0c4yc2wDxpIOiGfoOqJFxGcy862IGN7V/Zn55uGeSTpQBl2SCuGSi45oEfEe/7zUsufqilm9nZl5XEMGkw6AZ+iSVAjfWCRVRcS5EfGl6u3BEdHa6JmknvAMXQIi4nZgAjAiM0+JiM8CT2TmOQ0eTaqZZ+hSxVRgMrAFIDN/Dxzb0ImkHjLoUsX2rPy4uucTiwY0eB6pxwy6VPF4RMwFPhkRNwALgb9t8ExSj7iGLlVFxEXAF6qbCzLzl42cR+opX4cu/bOVwJ4Pil7Z4FmkHnPJRQIi4svAEuBK4C+BlyPi3zV2KqlnXHKR2PuJRWdn5qbq9iDgpcwc0djJpNp5hi5VbALe67T9XnWf1Gt4hi4BEfETYAzwNJU19CnAb6t/yMy7GzedVBt/KSpV/J/qnz2erv7tm4vUa3iGLkmF8AxdR7SI+F5m/vuI+Dldf2LR5AaMJR0Qg64j3cPVv7/d0CmkOnDJRUe0iOgHfAX4cypvJro/M3c2dirpwBh0HdEi4jFgB/Br4FLgzcy8ubFTSQfGoOuIFhErM3NM9XZfYElmntbgsaQD4huLdKTbseeGSy3q7TxD1xEtInZR/VALKh8M3R/Yih8SrV7IoEtSIVxykaRCGHRJKoRBl6RCGHRJKoRBl6RC/H+tO1mfV94Z6AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
        "grid_svc_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
        "y_pred = grid_svc.best_estimator_.predict(X_test)\n",
        "grid_svc_df.loc[grid_svc.best_estimator_.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
        "\n",
        "\n",
        "print(grid_svc.best_score_)\n",
        "print(grid_svc.best_params_)\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "\n",
        "# display the results of the classifiers in a comparison bar plot\n",
        "comparisonBarPlot = grid_svc_df.plot.bar()\n",
        "\n",
        "# display the results of the classifiers in a markdown table\n",
        "markDownTableResults = grid_svc_df.to_markdown()\n",
        "md(markDownTableResults)# # # # # # # # # # # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTvhS2V5tzMd"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.under_sampling import RandomUnderSampler \n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# -- Define the objective function\n",
        "def objective(trial):\n",
        "\n",
        "    # -- Instantiate selector\n",
        "    selector_threshold = trial.suggest_float('selector__threshold', 0.0, 0.1)\n",
        "\n",
        "    selector = VarianceThreshold(threshold=selector_threshold)\n",
        "\n",
        "    # -- Instantiate UnderSampler\n",
        "    rus = RandomUnderSampler()\n",
        "\n",
        "    # -- Instantiate scaler\n",
        "    # (a) List scalers to chose from\n",
        "    scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard'])\n",
        "\n",
        "    # (b) Define your scalers\n",
        "    if scalers == \"minmax\":\n",
        "        scaler = MinMaxScaler()\n",
        "    elif scalers == \"standard\":\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "    # -- Instantiate dimensionality reduction\n",
        "     # (a) List all dimensionality reduction options\n",
        "    dim_red = trial.suggest_categorical(\"dim_red\", [\"PCA\", None])\n",
        "\n",
        "    # (b) Define the PCA algorithm and its hyperparameters\n",
        "    if dim_red == \"PCA\":\n",
        "        pca_n_components=trial.suggest_int(\"pca_n_components\", 50, 171)\n",
        "        dimen_red_algorithm=PCA(n_components=pca_n_components)\n",
        "    # (c) No dimensionality reduction option\n",
        "    else:\n",
        "        dimen_red_algorithm='passthrough'\n",
        "\n",
        "\n",
        "   # -- Instantiate estimator model\n",
        "    C=trial.suggest_float('clf__C', 0.5, 1000.0)\n",
        "    kernel=trial.suggest_categorical('clf__kernel', ['rbf', 'poly', 'sigmoid', 'linear'])\n",
        "    gamma=trial.suggest_float('clf__gamma', 0.001,1)\n",
        "\n",
        "    estimator = SVC(C=C, kernel=kernel, gamma=gamma)\n",
        "\n",
        "    ##########\n",
        "\n",
        "\n",
        "    # -- Make a pipeline\n",
        "    pipeline = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', dimen_red_algorithm), ('clf', estimator)], memory = 'tmp')\n",
        "\n",
        "    # -- Evaluate the score by cross-validation\n",
        "    score = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=5)\n",
        "    acc = score.mean() # calculate the mean of scores\n",
        "    return acc\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\") # maximise the score during tuning\n",
        "study.optimize(objective, n_trials=20) # run the objective function 20 times\n",
        "\n",
        "print(study.best_trial) # print the best performing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRKHip3RwdI_",
        "outputId": "734624fa-8507-4df6-872a-6cdd818766d0"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "|          |   Accuracy |   F1 Score |\n",
              "|:---------|-----------:|-----------:|\n",
              "| Pipeline |   0.921717 |   0.921722 |"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Initialize the transformers without hyperparameters\n",
        "selector = VarianceThreshold(threshold=0.004018792290066309)\n",
        "scaler = MinMaxScaler()\n",
        "rus = RandomUnderSampler()\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipe_svc_optuna = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus),  ('clf', SVC(C=272.19639794978974,kernel=\"linear\", gamma=0.20803325037611617))], memory = 'tmp')\n",
        "\n",
        "\n",
        "# Fit the grid search\n",
        "pipe_svc_optuna.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
        "pipe_svc_optuna_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
        "y_pred = pipe_svc_optuna.predict(X_test)\n",
        "pipe_svc_optuna_df.loc[pipe_svc_optuna.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "\n",
        "# display the results of the classifiers in a comparison bar plot\n",
        "comparisonBarPlot = pipe_svc_optuna_df.plot.bar()\n",
        "\n",
        "# display the results of the classifiers in a markdown table\n",
        "markDownTableResults = pipe_svc_optuna_df.to_markdown()\n",
        "md(markDownTableResults)# # # # # # # # # # # \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itq3Y-uBwdJA"
      },
      "source": [
        "### **Conclusion for SVM:**\n",
        "\n",
        "Results |   Accuracy | \tF1 Score |\n",
        "----------- | ----------- | ----------- |\n",
        "Out of the box |\t0.838673 |\t0.812597 |\n",
        "Hyperparameter Optimization |\t0.930756 |\t0.930947  |\n",
        "Optuna |\t0.921717 |\t0.921722 |\n",
        "\n",
        "As we can see, we achieved considerable increases in performance by using hyperparameter optimization. The manual hyperparameter optimization was the most effective and produced the best model. That would be our selection for the best SVM estimator for our final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overall conclusion\n",
        "\n",
        "We have tested different models and hyperparameter optimization techniques. When we compare the best MLP and SVM models, we can see that the SVM model performs slightly better and is faster to train. We will choose the SVM model as our final model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "acfbf7094fff1dbd66caca67cfad89cabecb153e32a3d2d19e12a6db5744107a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
