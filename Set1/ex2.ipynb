{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "kChJDbhknE1X"
            },
            "source": [
                "### Dataset review\n",
                "\n",
                "- **Dataset presentation:** The dataset consists of online poker games. There are multiple columns represent the features of the game and the column named result is the label of the dataset which indicates the performance of the player.\n",
                "\n",
                "- **File conversion:** We did not need to convert the data format, we used the read_csv function from pandas.\n",
                "\n",
                "- **Entry count:** The dataset consists of 102615 entries. After carefully examining the dataset, we found that there was just one player with id=fa538846 who had sufficient data to be considered. All the others had missing data essential for the analysis. Therefore, we decided to remove all the players except for the one. This resulted in a dataset with 41303 entries.\n",
                "\n",
                "- **Attribute count:** The dataset consists of 35 attributes with many different types. There are categorical, nominal, numerical and binary data types. More precisely all the columns related to card values such as cards, board_flop, board_turn etc are ordinal because they have a natural order. Other columns that describe some actions of the game such as call, raise etc are nominal and we used one hot encoding to replace them with binary features. There is one binary column called all_in and the rest of them are numerical. The label column with name result is categorical. During the analysis we understood that there are some columns that are not useful and we decided to remove them. The dropped columns are: buyin, tourn_id, table, hand_id, date, time, table_size, seat, name and combination. Additionally, we decided to remove the column with name balance because it provides information on the final result (which is what we want to predict) and we do not want to use it as a feature.\n",
                "\n",
                "- **Indexes and headers:** There are row indexes and column headers.\n",
                "\n",
                "- **Class labels:** Class labels (found in column 34) are categorical and represent if the player won, lost, gave up or took chips. \n",
                "\n",
                "- **Missing values:** There is just one column with missing values, the column named combination in which the 82% are missing values. Considering the content of the column which is the cards combination of each player we thought that the replication of missing rows does not make any sense. Apart from this, the big amount of missing values was another indication that this column should be removed from the training process.\n",
                "\n",
                "- **Class count:** As we can see from the table below, the dataset is not balanced.\n",
                "\n",
                "Class      | Number of instances | Percentages |\n",
                "----------- | ----------- | ----------- |\n",
                "won      | 4228       | 10.2% |\n",
                "lost         | 3570       | 8.6% |\n",
                "gave up   | 21359        | 51.7% |\n",
                "took chips         | 12146       | 29.5% |\n",
                "    \n",
                "\n",
                "\n",
                "      \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "id": "UdcAWbV7nE1d"
            },
            "outputs": [],
            "source": [
                "# from google.colab import drive \n",
                "# drive.mount('/content/gdrive')\n",
                "\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import sklearn as sk\n",
                "import matplotlib as mpl\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from sklearn.preprocessing import OrdinalEncoder\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "\n",
                "\n",
                "# dataset_path = \"/content/gdrive/MyDrive/Datasets/one_dollar_spin_and_go.csv\"\n",
                "\n",
                "# Set the working directory\n",
                "root_dir = \"Datasets\"\n",
                "\n",
                "# # Read dataset and save it in a dataframe\n",
                "df = pd.read_csv(os.path.join(root_dir, \"one_dollar_spin_and_go.csv\"),  delimiter=\",\")\n",
                "\n",
                "# df = pd.read_csv(dataset_path)\n",
                "\n",
                "\n",
                "# keep rows with name = fa538846\n",
                "df = df[df['name'] == 'fa538846']\n",
                "\n",
                "\n",
                "df.reset_index(drop=True, inplace=True)\n",
                "# drop columns\n",
                "df = df.drop(['buyin', 'tourn_id', 'table', 'hand_id', 'date', 'time','table_size' ,'seat', 'name', 'combination','balance'], axis=1)\n",
                "\n",
                "\n",
                "# From column 'cards' we create 5 new columns for each card x={1,2} ('card_value_x', 'card_suit__c', 'card_suit__d', 'card_suit__h', 'card_suit__s')\n",
                "# We will use OrdinalEncoder to transform the values of the columns 'card_value_x' into numerical values\n",
                "# We will use OneHotEncoder to transform the values of the columns 'card_suit_x' into several columns with binary values\n",
                "\n",
                "df['card_value_1'] = df['cards'].str.split(' ').str[0].str[0]\n",
                "df['card_suit_1'] = df['cards'].str.split(' ').str[0].str[1]\n",
                "df['card_value_2'] = df['cards'].str.split(' ').str[1].str[0]\n",
                "df['card_suit_2'] = df['cards'].str.split(' ').str[1].str[1]\n",
                "\n",
                "\n",
                "# define ordinal encoder with playing card values as categories\n",
                "ordinal_encoder_cards = OrdinalEncoder(categories=[['0','2', '3', '4', '5', '6', '7', '8', '9', 'T', 'J', 'Q', 'K', 'A']])\n",
                "\n",
                "# fit and transform the card_value_1 and card_value_2 columns\n",
                "df['card_value_1'] = ordinal_encoder_cards.fit_transform(df[['card_value_1']])\n",
                "df['card_value_2'] = ordinal_encoder_cards.fit_transform(df[['card_value_2']])\n",
                "\n",
                "\n",
                "# define one hot encoder for card_suit_1 and card_suit_2\n",
                "one_hot_encoder = sk.preprocessing.OneHotEncoder(sparse=False)\n",
                "\n",
                "\n",
                "# use one hot encoder to transform card_suit_1 and card_suit_2 and save the result in new columns\n",
                "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['card_suit_1', 'card_suit_2']]))\n",
                "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
                "\n",
                "df = pd.concat([df, oneHotEncodedDf], axis=1 )\n",
                "\n",
                "\n",
                "# do the same as above for the columns board_flop, board_turn and board_river if values is not 0\n",
                "# replace 0 with \"00 00 00\"\n",
                "df['board_flop'] = df['board_flop'].replace('0', '00 00 00')\n",
                "\n",
                "df['board_flop_1'] = df['board_flop'].str.split(' ').str[0].str[0]\n",
                "df['board_flop_suit_1'] = df['board_flop'].str.split(' ').str[0].str[1]\n",
                "df['board_flop_2'] = df['board_flop'].str.split(' ').str[1].str[0]\n",
                "df['board_flop_suit_2'] = df['board_flop'].str.split(' ').str[1].str[1]\n",
                "df['board_flop_3'] = df['board_flop'].str.split(' ').str[2].str[0]\n",
                "df['board_flop_suit_3'] = df['board_flop'].str.split(' ').str[2].str[1]\n",
                "\n",
                "df['board_flop_1'] = ordinal_encoder_cards.fit_transform(df[['board_flop_1']])\n",
                "df['board_flop_2'] = ordinal_encoder_cards.fit_transform(df[['board_flop_2']])\n",
                "df['board_flop_3'] = ordinal_encoder_cards.fit_transform(df[['board_flop_3']])\n",
                "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['board_flop_suit_1', 'board_flop_suit_2', 'board_flop_suit_3']]))\n",
                "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
                "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
                "\n",
                "# replace 0 with \"00\"\n",
                "df['board_turn'] = df['board_turn'].replace('0', '00')\n",
                "\n",
                "df['board_turn_value'] = df['board_turn'].str.split(' ').str[0].str[0]\n",
                "df['board_turn_suit'] = df['board_turn'].str.split(' ').str[0].str[1]\n",
                "df['board_turn_value'] = ordinal_encoder_cards.fit_transform(df[['board_turn_value']])\n",
                "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['board_turn_suit']]))\n",
                "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
                "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
                "\n",
                "# replace 0 with \"00\"\n",
                "df['board_river'] = df['board_river'].replace('0', '00')\n",
                "\n",
                "df['board_river_value'] = df['board_river'].str.split(' ').str[0].str[0]\n",
                "df['board_river_suit'] = df['board_river'].str.split(' ').str[0].str[1]\n",
                "df['board_river_value'] = ordinal_encoder_cards.fit_transform(df[['board_river_value']])\n",
                "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['board_river_suit']]))\n",
                "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
                "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
                "\n",
                "# drop the columns\n",
                "df = df.drop(['cards', 'card_suit_1', 'card_suit_2', 'board_flop', 'board_turn', 'board_river', 'board_flop_suit_1', 'board_flop_suit_2', 'board_flop_suit_3', 'board_turn_suit', 'board_river_suit'], axis=1)\n",
                "\n",
                "\n",
                "# use one hot on the columns 'position', 'action_pre', 'action_flop', 'action_turn', 'action_river'\n",
                "oneHotEncodedDf = pd.DataFrame(one_hot_encoder.fit_transform(df[['position', 'action_pre', 'action_flop', 'action_turn', 'action_river']]))\n",
                "oneHotEncodedDf.columns = one_hot_encoder.get_feature_names_out()\n",
                "df = pd.concat([df, oneHotEncodedDf], axis=1)\n",
                "df = df.drop(['position', 'action_pre', 'action_flop', 'action_turn', 'action_river'], axis=1)\n",
                "\n",
                "# use label encoder on the column 'result'\n",
                "label_encoder = sk.preprocessing.LabelEncoder()\n",
                "df['result'] = label_encoder.fit_transform(df['result'])\n",
                "\n",
                "y= df['result']\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "vavS9F__tUmI"
            },
            "source": [
                "### Dataset split\n",
                "\n",
                "- **Splitting method:** We used the train_test_split function from sklearn.model_selection to split the dataset into training and testing sets. We used a 70/30 split, meaning that 70% of the dataset was used for training and 30% for testing. We selected this ratio because we wanted to have a good amount of data for training and at the same time we wanted to have enough data for testing.\n",
                "\n",
                "- **Cross validation:**  We used 10 fold cross validation because we undersampled the classes to make the dataset balanced. This way we weren't too concerned about a class not being present in our training set and we used 5 folds to save time. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "id": "AcStrfksnE1g"
            },
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Split the data into training and test sets\n",
                "X = df.drop(['result'], axis=1)\n",
                "y= df['result']\n",
                "\n",
                "#split the df into train and test sets with 30% of the data in the test set\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "jjDHo0jLu2zX"
            },
            "source": [
                "### Dataset metrics\n",
                "\n",
                "- **Metric selection:** We used the accuracy score and the f1_micro as the metrics for evaluating the performance of the models. As about the accuracy score it is considered the most common metric for classification problems. It is also easy to understand and interpret. The accuracy score is the ratio of the number of correct predictions to the total number of predictions. It is a good metric for our problem because we want to know how many times the model predicted the correct class. The f1_micro is the harmonic mean of the precision and recall. It is a good metric for our problem because we want to know how many times the model predicted the correct class and how many times it predicted the wrong class. The f1_micro is a good metric for our problem because we want to know how many times the model predicted the correct class and how many times it predicted the wrong class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "id": "HmZRP-tBnE1g"
            },
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.metrics import f1_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "BJiKu-mWnE1g"
            },
            "outputs": [],
            "source": [
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.dummy import DummyClassifier\n",
                "\n",
                "# create a list of models\n",
                "models = []\n",
                "models.append(DummyClassifier())\n",
                "models.append(MLPClassifier())\n",
                "models.append(SVC())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Out of the box performance\n",
                "\n",
                "- **OOB classifiers:** As we can see from the below results the MLPClassifier has better performance metrics in comparison with the SVC classifier but both of them have very good performance metrics even without tuning the hyperparameters. This shows that the default hyperparameters may be good enough for this dataset's analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 427
                },
                "id": "Nbt_baAOnE1g",
                "outputId": "1dab61c2-0605-47fe-9cec-30cc2741801c"
            },
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "|                 |   Accuracy OOB |   F1 Score OOB |\n",
                            "|:----------------|---------------:|---------------:|\n",
                            "| DummyClassifier |       0.514809 |       0.349917 |\n",
                            "| MLPClassifier   |       0.913566 |       0.903664 |\n",
                            "| SVC             |       0.838673 |       0.812597 |"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
                "out_of_the_box_df = pd.DataFrame(columns=['Accuracy OOB', 'F1 Score OOB'])\n",
                "for clf in models:\n",
                "    clf.fit(X_train, y_train)\n",
                "    y_pred = clf.predict(X_test)\n",
                "    out_of_the_box_df.loc[clf.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
                "\n",
                "\n",
                "from IPython.display import Markdown as md\n",
                "\n",
                "\n",
                "# display the results of the classifiers in a comparison bar plot\n",
                "comparisonBarPlot = out_of_the_box_df.plot.bar()\n",
                "\n",
                "# display the results of the classifiers in a markdown table\n",
                "markDownTableResults = out_of_the_box_df.to_markdown()\n",
                "md(markDownTableResults)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "V2cCy5U6nE1h"
            },
            "source": [
                "### **MLP Classifier training**\n",
                "\n",
                "#### **Data preprocessing:** We tested a combination of data preprocessing techniques, including:\n",
                "\n",
                "- **Standardization:** We used the MinMaxScaler for standarisizing the data. We did not use the StandardScaler because it is sensitive to outliers.\n",
                "\n",
                "- **Feature selection:** We used the VarianceThreshold to remove features with low variance. We tested thresholds from 0.0 to 0.1 and we found that 0.0 is the best option.\n",
                "\n",
                "- **Sampling:** We used the RandomUnderSampler undersample the majority classes. We avoided using the oversampling techniques because we had a large volume of data and we wanted to avoid overfitting and large training times.\n",
                "\n",
                "- **Feature extraction:** We used the PCA to reduce the dimensionality of the data. We tested the number of components from 1% to 99% and we found that 99% is the best option. In the end we found out that PCA does not make a differenence so we removed it.\n",
                "\n",
                "<br/>\n",
                "\n",
                "\n",
                "#### **MLP Classifier:** We used the MLPClassifier from sklearn.neural_network to train our model. We tested different combinations of parameters and we found that the best combination is:\n",
                "\n",
                "\n",
                "<br/>\n",
                "\n",
                "#### **Hyperparameter tuning methodology:** We used the both HalvingRandomSearchCV and HalvingGridSearchCV to find the best combination of parameters. We began with the HalvingRandomSearchCV and we tested a large spectrum of choices for every hyperparameter. We then used the HalvingGridSearchCV to narrow down the choices for every hyperparameter. In the end, we used the HalvingGridSearchCV to find the best combination of parameters, based on the results we found on our previous tests. In our first two tests, we used the exact same parameters without narrowing them down but we changed the scoring function to from accuracy to f1_micro. We found that the best results occured when we used the f1_micro scoring function, so we used it for the rest of the tests.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Cg7WOYlWnE1h"
            },
            "source": [
                "### **Test results and analysis:**\n",
                "\n",
                "#### **Test 1 HalvingRandomSearchCV with scoring = 'accuracy'**\n",
                "\n",
                "##### **Test parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | [0.0, 0.05, 0.1] |\n",
                "pca__n_components | [0.1, 0.35, 0.75, 0.9] |\n",
                "clf__solver | ['sgd', 'adam'] |\n",
                "clf__activation | ['tanh', 'relu'] |\n",
                "clf__alpha | [0.01, 0.1, 0.5, 1, 2] |\n",
                "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100), (100, 100, 100, 100)] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | 0.0 |\n",
                "pca__n_components | 0.9 |\n",
                "clf__solver | adam |\n",
                "clf__activation | tanh |\n",
                "clf__alpha | 0.1 |\n",
                "clf__hidden_layer_sizes | (100, 100)\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.907917 |\t0.909672 |\n",
                "\n",
                "##### **Comment:** These scores will be used to compare the accuracy and f1 micro scoring functions.\n",
                "\n",
                "<br/>\n",
                "\n",
                "#### **Test 2 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
                "\n",
                "##### **Test parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | [0.0, 0.05, 0.1] |\n",
                "pca__n_components | [0.1, 0.35, 0.75, 0.9] |\n",
                "clf__solver | ['sgd', 'adam'] |\n",
                "clf__activation | ['tanh', 'relu'] |\n",
                "clf__alpha | [0.01, 0.1, 0.5, 1, 2] |\n",
                "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100), (100, 100, 100, 100)] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | 0.0 |\n",
                "pca__n_components | 0.9 |\n",
                "clf__solver | adam |\n",
                "clf__activation | tanh |\n",
                "clf__alpha | 0.1 |\n",
                "clf__hidden_layer_sizes | (100, 100)\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.919538 |\t0.920614 |\n",
                "\n",
                "##### **Comment:** Comparing the scores of test 1 and 2, we came to the conclusion that the f1_micro scoring function produces better results, so we will use it in our next tests. For the next test we will narrow down the values for every hyperparameter to values closer to the optimal value from this test.\n",
                "\n",
                "<br/>\n",
                "\n",
                "#### **Test 3 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
                "\n",
                "\n",
                "##### **Test parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | [0.0, 0.02, 0.5] |\n",
                "pca__n_components | [0.85, 0.9, 0.99] |\n",
                "clf__solver | ['sgd', 'adam'] |\n",
                "clf__activation | ['tanh', 'relu'] |\n",
                "clf__alpha | [0.05, 0.1, 0.15] |\n",
                "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100), (100, 100, 100, 100)] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | 0.0 |\n",
                "pca__n_components | 0.99 |\n",
                "clf__solver | adam |\n",
                "clf__activation | tanh |\n",
                "clf__alpha | 0.05 |\n",
                "clf__hidden_layer_sizes | (100, 100)\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.910096 |\t0.911866 |\n",
                "\n",
                "##### **Comment:** As we can see, the hyperparameters clf__solver and clf__activation always work better with the values 'adam' and 'tanh'. These will be our final values for those hyperparameters and we will stop testing for them. We also see the same pattern for clf__hidden_layer_sizes, we will continue testing but only choices closer to the (100, 100) choice.\n",
                "\n",
                "<br/>\n",
                "\n",
                "#### **Test 4 GridSearchCV with scoring = 'f1_micro'**\n",
                "\n",
                "\n",
                "##### **Test parameters:**\n",
                "\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | [0.0, 0.01] |\n",
                "pca__n_components | [0.98, 0.99] |\n",
                "clf__alpha | [0.02, 0.05, 0.07] |\n",
                "clf__hidden_layer_sizes | [(100, 100), (100, 100, 100)] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "selector__threshold | 0.0 |\n",
                "pca__n_components | 0.99 |\n",
                "clf__alpha | 0.07 |\n",
                "clf__hidden_layer_sizes | (100, 100)\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.912194 |\t0.913875 |\n",
                "\n",
                "##### **Comment:** Since the hyperparameter values were almost completely optimized, we used GridSearchCV for our last test, because training time was not a problem (few combinations needed to be tested). The final testing score was marginally better than the previous versions.\n",
                "\n",
                "<br/>\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "sr0olIVsnE1h",
                "outputId": "11e00690-59d6-4077-bc16-f4522850baa7"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "GridSearchCV(cv=10,\n",
                            "             estimator=Pipeline(memory='tmp',\n",
                            "                                steps=[('selector', VarianceThreshold()),\n",
                            "                                       ('scaler', MinMaxScaler()),\n",
                            "                                       ('rus', RandomUnderSampler()),\n",
                            "                                       ('pca', PCA()),\n",
                            "                                       ('clf',\n",
                            "                                        MLPClassifier(activation='tanh'))]),\n",
                            "             n_jobs=-1,\n",
                            "             param_grid={'clf__alpha': [0.02, 0.05, 0.07],\n",
                            "                         'clf__hidden_layer_sizes': [(100, 100),\n",
                            "                                                     (100, 100, 100)],\n",
                            "                         'pca__n_components': [0.98, 0.99],\n",
                            "                         'selector__threshold': [0.0, 0.01]},\n",
                            "             scoring='f1_micro', verbose=1)"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from imblearn.over_sampling import RandomOverSampler\n",
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.pipeline import Pipeline\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "from sklearn.experimental import enable_halving_search_cv\n",
                "# from sklearn.model_selection import HalvingGridSearchCV\n",
                "from sklearn.model_selection import HalvingRandomSearchCV\n",
                "\n",
                "\n",
                "# Initialize the transformers without hyperparameters\n",
                "selector = VarianceThreshold()\n",
                "scaler = MinMaxScaler()\n",
                "rus = RandomUnderSampler()\n",
                "pca = PCA()\n",
                "\n",
                "# Initialize the pipeline\n",
                "pipe_mlp = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', pca), ('clf', MLPClassifier(solver=\"adam\", activation=\"tanh\"))], memory = 'tmp')\n",
                "\n",
                "# Define the hyperparameters\n",
                "param_grid_mlp = {\n",
                "    'selector__threshold': [0.0, 0.01],\n",
                "    'pca__n_components': [0.98, 0.99],\n",
                "    'clf__alpha': [0.02, 0.05, 0.07],\n",
                "    'clf__hidden_layer_sizes': [(100, 100), (100, 100, 100)]\n",
                "} \n",
                "\n",
                "# Initialize the HalvingRandomSearchCV search\n",
                "grid_mlp = GridSearchCV(pipe_mlp, param_grid_mlp, cv=10, n_jobs=-1, verbose=1, scoring='f1_micro')\n",
                "\n",
                "# Fit the grid search\n",
                "grid_mlp.fit(X_train, y_train)\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 373
                },
                "id": "Isz_hb7ynE1i",
                "outputId": "1bf00bcc-d026-4d59-f60c-8a56dd9eee03"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.9106945506946008\n",
                        "{'clf__alpha': 0.07, 'clf__hidden_layer_sizes': (100, 100), 'pca__n_components': 0.99, 'selector__threshold': 0.0}\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "|          |   Accuracy |   F1 Score |\n",
                            "|:---------|-----------:|-----------:|\n",
                            "| Pipeline |   0.912194 |   0.913875 |"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
                "grid_mlp_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
                "y_pred = grid_mlp.best_estimator_.predict(X_test)\n",
                "grid_mlp_df.loc[grid_mlp.best_estimator_.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
                "\n",
                "\n",
                "print(grid_mlp.best_score_)\n",
                "print(grid_mlp.best_params_)\n",
                "\n",
                "from IPython.display import Markdown as md\n",
                "\n",
                "\n",
                "# display the results of the classifiers in a comparison bar plot\n",
                "comparisonBarPlot = grid_mlp_df.plot.bar()\n",
                "\n",
                "# display the results of the classifiers in a markdown table\n",
                "markDownTableResults = grid_mlp_df.to_markdown()\n",
                "md(markDownTableResults)# # # # # # # # # # # "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "ShfS4lIqnE1i",
                "outputId": "f17bda75-f0f9-428e-e656-b650e11edb11"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m[I 2022-11-28 14:35:59,690]\u001b[0m A new study created in memory with name: no-name-7e3977a3-257d-41fb-8c0e-bd5b90834297\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 14:39:09,184]\u001b[0m Trial 0 finished with value: 0.9261206689318809 and parameters: {'selector__threshold': 0.0024547727859665306, 'scalers': 'standard', 'dim_red': None, 'clf__alpha': 1.8745876376736077, 'clf__solver': 'sgd', 'clf__activation': 'relu'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 14:40:39,940]\u001b[0m Trial 1 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 14:43:30,993]\u001b[0m Trial 2 finished with value: 0.8358813954688813 and parameters: {'selector__threshold': 0.05787734573182857, 'scalers': 'minmax', 'dim_red': None, 'clf__alpha': 1.1492184024411989, 'clf__solver': 'sgd', 'clf__activation': 'tanh'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 14:46:24,141]\u001b[0m Trial 3 finished with value: 0.8224267768461969 and parameters: {'selector__threshold': 0.06664106090925977, 'scalers': 'standard', 'dim_red': 'PCA', 'pca_n_components': 50, 'clf__alpha': 0.30935286310737786, 'clf__solver': 'sgd', 'clf__activation': 'tanh'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 14:47:44,250]\u001b[0m Trial 4 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 14:48:26,763]\u001b[0m Trial 5 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 14:51:02,199]\u001b[0m Trial 6 finished with value: 0.8642776484445248 and parameters: {'selector__threshold': 0.0005599482727584038, 'scalers': 'minmax', 'dim_red': 'PCA', 'pca_n_components': 56, 'clf__alpha': 1.6456144443459104, 'clf__solver': 'adam', 'clf__activation': 'tanh'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 14:52:30,317]\u001b[0m Trial 7 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 14:53:56,443]\u001b[0m Trial 8 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 14:57:13,721]\u001b[0m Trial 9 finished with value: 0.9004912536913112 and parameters: {'selector__threshold': 0.012793814280627692, 'scalers': 'standard', 'dim_red': None, 'clf__alpha': 0.8872455955971769, 'clf__solver': 'sgd', 'clf__activation': 'relu'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 14:58:26,783]\u001b[0m Trial 10 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 15:00:22,996]\u001b[0m Trial 11 finished with value: 0.8300371028694716 and parameters: {'selector__threshold': 0.06142054081336588, 'scalers': 'minmax', 'dim_red': None, 'clf__alpha': 0.7535103004753132, 'clf__solver': 'adam', 'clf__activation': 'tanh'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 15:01:22,078]\u001b[0m Trial 12 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 15:02:12,426]\u001b[0m Trial 13 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 15:04:27,065]\u001b[0m Trial 14 finished with value: 0.8627902917776928 and parameters: {'selector__threshold': 0.027498763274196605, 'scalers': 'standard', 'dim_red': 'PCA', 'pca_n_components': 54, 'clf__alpha': 0.1468015578262337, 'clf__solver': 'adam', 'clf__activation': 'relu'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 15:07:07,993]\u001b[0m Trial 15 finished with value: 0.9211745049077816 and parameters: {'selector__threshold': 0.003902491811909781, 'scalers': 'minmax', 'dim_red': None, 'clf__alpha': 0.48343268658476823, 'clf__solver': 'adam', 'clf__activation': 'relu'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 15:09:24,135]\u001b[0m Trial 16 finished with value: 0.8322149039160033 and parameters: {'selector__threshold': 0.0845466221492684, 'scalers': 'standard', 'dim_red': None, 'clf__alpha': 1.4956817075446085, 'clf__solver': 'sgd', 'clf__activation': 'tanh'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[32m[I 2022-11-28 15:11:41,746]\u001b[0m Trial 17 finished with value: 0.8373339646441613 and parameters: {'selector__threshold': 0.055815161345689396, 'scalers': 'minmax', 'dim_red': None, 'clf__alpha': 1.0970300752179243, 'clf__solver': 'sgd', 'clf__activation': 'tanh'}. Best is trial 0 with value: 0.9261206689318809.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 15:12:58,403]\u001b[0m Trial 18 failed because of the following error: The value nan is not acceptable.\u001b[0m\n",
                        "\u001b[33m[W 2022-11-28 15:13:26,276]\u001b[0m Trial 19 failed because of the following error: The value nan is not acceptable.\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "FrozenTrial(number=0, values=[0.9261206689318809], datetime_start=datetime.datetime(2022, 11, 28, 14, 35, 59, 695775), datetime_complete=datetime.datetime(2022, 11, 28, 14, 39, 9, 183554), params={'selector__threshold': 0.0024547727859665306, 'scalers': 'standard', 'dim_red': None, 'clf__alpha': 1.8745876376736077, 'clf__solver': 'sgd', 'clf__activation': 'relu'}, distributions={'selector__threshold': FloatDistribution(high=0.1, log=False, low=0.0, step=None), 'scalers': CategoricalDistribution(choices=('minmax', 'standard')), 'dim_red': CategoricalDistribution(choices=('PCA', None)), 'clf__alpha': FloatDistribution(high=2.0, log=False, low=0.01, step=None), 'clf__solver': CategoricalDistribution(choices=('adam', 'sgd')), 'clf__activation': CategoricalDistribution(choices=('relu', 'tanh'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=0, state=TrialState.COMPLETE, value=None)\n"
                    ]
                }
            ],
            "source": [
                "import optuna\n",
                "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from imblearn.under_sampling import RandomUnderSampler \n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from imblearn.pipeline import Pipeline\n",
                "from sklearn.model_selection import cross_val_score\n",
                "import numpy as np\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "\n",
                "\n",
                "# -- Define the objective function\n",
                "def objective(trial):\n",
                "\n",
                "    # -- Instantiate selector\n",
                "    selector_threshold = trial.suggest_float('selector__threshold', 0.0, 0.1)\n",
                "\n",
                "    selector = VarianceThreshold(threshold=selector_threshold)\n",
                "\n",
                "    # -- Instantiate UnderSampler\n",
                "    rus = RandomUnderSampler()\n",
                "\n",
                "    # -- Instantiate scaler\n",
                "    # (a) List scalers to chose from\n",
                "    scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard'])\n",
                "\n",
                "    # (b) Define your scalers\n",
                "    if scalers == \"minmax\":\n",
                "        scaler = MinMaxScaler()\n",
                "    elif scalers == \"standard\":\n",
                "        scaler = StandardScaler()\n",
                "\n",
                "    # -- Instantiate dimensionality reduction\n",
                "     # (a) List all dimensionality reduction options\n",
                "    dim_red = trial.suggest_categorical(\"dim_red\", [\"PCA\", None])\n",
                "\n",
                "    # (b) Define the PCA algorithm and its hyperparameters\n",
                "    if dim_red == \"PCA\":\n",
                "        pca_n_components=trial.suggest_int(\"pca_n_components\", 50, 171)\n",
                "        dimen_red_algorithm=PCA(n_components=pca_n_components)\n",
                "    # (c) No dimensionality reduction option\n",
                "    else:\n",
                "        dimen_red_algorithm='passthrough'\n",
                "\n",
                "    # -- Instantiate estimator model\n",
                "    alpha=trial.suggest_float('clf__alpha', 0.01, 2.0)\n",
                "    solver=trial.suggest_categorical('clf__solver', ['adam', 'sgd'])\n",
                "    activation=trial.suggest_categorical('clf__activation', ['relu', 'tanh'])\n",
                "\n",
                "    estimator = MLPClassifier(alpha=alpha, solver=solver, activation=activation)\n",
                "\n",
                "    ##########\n",
                "\n",
                "\n",
                "    # -- Make a pipeline\n",
                "    pipeline = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', dimen_red_algorithm), ('clf', estimator)], memory = 'tmp')\n",
                "\n",
                "    # -- Evaluate the score by cross-validation\n",
                "    score = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=5)\n",
                "    acc = score.mean() # calculate the mean of scores\n",
                "    return acc\n",
                "\n",
                "study = optuna.create_study(direction=\"maximize\") # maximise the score during tuning\n",
                "study.optimize(objective, n_trials=20) # run the objective function 20 times\n",
                "\n",
                "print(study.best_trial) # print the best performing pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 339
                },
                "id": "y7RUUhkG4PKk",
                "outputId": "a7be5143-439a-4651-e4b4-35fcc1209edb"
            },
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "|          |   Accuracy |   F1 Score |\n",
                            "|:---------|-----------:|-----------:|\n",
                            "| Pipeline |   0.924784 |   0.925889 |"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "#  params={'selector__threshold': 0.0024547727859665306, 'scalers': 'standard', 'dim_red': None, 'clf__alpha': 1.8745876376736077, 'clf__solver': 'sgd', 'clf__activation': 'relu'}\n",
                "\n",
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.pipeline import Pipeline\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "\n",
                "\n",
                "# Initialize the transformers without hyperparameters\n",
                "selector = VarianceThreshold(threshold=0.0024547727859665306)\n",
                "scaler = StandardScaler()\n",
                "rus = RandomUnderSampler()\n",
                "\n",
                "# Initialize the pipeline\n",
                "pipe_mlp_optuna = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus),  ('clf', MLPClassifier(alpha=1.8745876376736077,solver=\"sgd\", activation=\"relu\"))], memory = 'tmp')\n",
                "\n",
                "\n",
                "# Fit the grid search\n",
                "pipe_mlp_optuna.fit(X_train, y_train)\n",
                "\n",
                "\n",
                "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
                "pipe_mlp_optuna_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
                "y_pred = pipe_mlp_optuna.predict(X_test)\n",
                "pipe_mlp_optuna_df.loc[pipe_mlp_optuna.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
                "\n",
                "\n",
                "\n",
                "from IPython.display import Markdown as md\n",
                "\n",
                "\n",
                "# display the results of the classifiers in a comparison bar plot\n",
                "comparisonBarPlot = pipe_mlp_optuna_df.plot.bar()\n",
                "\n",
                "# display the results of the classifiers in a markdown table\n",
                "markDownTableResults = pipe_mlp_optuna_df.to_markdown()\n",
                "md(markDownTableResults)# # # # # # # # # # # \n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Conclusion for MLP:**\n",
                "\n",
                "Results |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Out of the box |\t0.913566  |\t0.903664 |\n",
                "Hyperparameter Optimization |\t0.912194 | 0.913875 |\n",
                "Optuna |\t0.924784 |  0.925889 |\n",
                "\n",
                "As we can see, we achieved minor increases in performance by using hyperparameter optimization. The Optuna hyperparameter optimization was the most effective, easier to set up and faster to run. Mainly based on the performance results, we will consider this as the best MLP estimator for our final model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "FHlKj9pEc77T"
            },
            "source": [
                "### **Test results and analysis SVC:**\n",
                "\n",
                "#### **Test 1 HalvingRandomSearchCV with scoring = 'accuracy'**\n",
                "\n",
                "##### **Test parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | [0.1, 1, 10, 100, 1000] |\n",
                "clf__gamma | [1, 0.1, 0.01, 0.001, 0.0001] |\n",
                "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | 10 |\n",
                "clf__gamma | 0.01 |\n",
                "clf__kernel | linear |\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.930918 |\t0.931034 |\n",
                "\n",
                "##### **Comment:** These scores will be used to compare the accuracy and f1 micro scoring functions.\n",
                "\n",
                "<br/>\n",
                "\n",
                "#### **Test 2 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
                "\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | [0.1, 1, 10, 100, 1000] |\n",
                "clf__gamma | [1, 0.1, 0.01, 0.001, 0.0001] |\n",
                "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | 100 |\n",
                "clf__gamma | 1 |\n",
                "clf__kernel | linear |\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.930998 |\t0.931106 |\n",
                "\n",
                "##### **Comment:** Comparing the scores of test 1 and 2, we came to the conclusion that both the f1_micro and accuracy scoring functions produce similar results. We choose to use the f1_micro in our next tests. For the next test we will narrow down the values for every hyperparameter to values closer to the optimal value from this test.\n",
                "\n",
                "<br/>\n",
                "\n",
                "#### **Test 3 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
                "\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | [90, 100, 500] |\n",
                "clf__gamma | [1.1, 1, 0.9] |\n",
                "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | 110 |\n",
                "clf__gamma | 1 |\n",
                "clf__kernel | linear |\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.937212 |\t0.937323 |\n",
                "\n",
                "##### **Comment:** The linear clf kernel performs always better and that's why we we pick it as the classifier kernel.\n",
                "\n",
                "#### **Test 4 HalvingRandomSearchCV with scoring = 'f1_micro'**\n",
                "\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | [90, 100, 110] |\n",
                "clf__gamma | [0.8, 0.9, 1] |\n",
                "clf__kernel | ['rbf', 'poly', 'sigmoid', 'linear'] |\n",
                "\n",
                "##### **Best parameters:**\n",
                "\n",
                "Hyperparameter | Values |\n",
                "----------- | ----------- |\n",
                "clf__C | 110 |\n",
                "clf__gamma | 1 |\n",
                "clf__kernel | linear |\n",
                "\n",
                "\n",
                "##### **Test score:**\n",
                "Scores |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Pipeline |\t0.937212 |\t0.937323 |\n",
                "\n",
                "##### **Comment:** The linear clf kernel performs always better and that's why we we pick it as the classifier kernel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "id": "v499vz4EdGfV"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "n_iterations: 3\n",
                        "n_required_iterations: 3\n",
                        "n_possible_iterations: 6\n",
                        "min_resources_: 80\n",
                        "max_resources_: 28912\n",
                        "aggressive_elimination: False\n",
                        "factor: 3\n",
                        "----------\n",
                        "iter: 0\n",
                        "n_candidates: 12\n",
                        "n_resources: 80\n",
                        "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
                        "----------\n",
                        "iter: 1\n",
                        "n_candidates: 4\n",
                        "n_resources: 240\n",
                        "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
                        "----------\n",
                        "iter: 2\n",
                        "n_candidates: 2\n",
                        "n_resources: 720\n",
                        "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingRandomSearchCV(cv=10,\n",
                            "                      estimator=Pipeline(memory=&#x27;tmp&#x27;,\n",
                            "                                         steps=[(&#x27;selector&#x27;,\n",
                            "                                                 VarianceThreshold()),\n",
                            "                                                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
                            "                                                (&#x27;rus&#x27;, RandomUnderSampler()),\n",
                            "                                                (&#x27;pca&#x27;, PCA()),\n",
                            "                                                (&#x27;clf&#x27;, SVC())]),\n",
                            "                      n_jobs=-1,\n",
                            "                      param_distributions={&#x27;clf__C&#x27;: [500],\n",
                            "                                           &#x27;clf__gamma&#x27;: [1.1, 1, 0.9],\n",
                            "                                           &#x27;clf__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;,\n",
                            "                                                           &#x27;sigmoid&#x27;,\n",
                            "                                                           &#x27;linear&#x27;]},\n",
                            "                      scoring=&#x27;f1_micro&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingRandomSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingRandomSearchCV(cv=10,\n",
                            "                      estimator=Pipeline(memory=&#x27;tmp&#x27;,\n",
                            "                                         steps=[(&#x27;selector&#x27;,\n",
                            "                                                 VarianceThreshold()),\n",
                            "                                                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
                            "                                                (&#x27;rus&#x27;, RandomUnderSampler()),\n",
                            "                                                (&#x27;pca&#x27;, PCA()),\n",
                            "                                                (&#x27;clf&#x27;, SVC())]),\n",
                            "                      n_jobs=-1,\n",
                            "                      param_distributions={&#x27;clf__C&#x27;: [500],\n",
                            "                                           &#x27;clf__gamma&#x27;: [1.1, 1, 0.9],\n",
                            "                                           &#x27;clf__kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;,\n",
                            "                                                           &#x27;sigmoid&#x27;,\n",
                            "                                                           &#x27;linear&#x27;]},\n",
                            "                      scoring=&#x27;f1_micro&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;tmp&#x27;,\n",
                            "         steps=[(&#x27;selector&#x27;, VarianceThreshold()), (&#x27;scaler&#x27;, MinMaxScaler()),\n",
                            "                (&#x27;rus&#x27;, RandomUnderSampler()), (&#x27;pca&#x27;, PCA()), (&#x27;clf&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "HalvingRandomSearchCV(cv=10,\n",
                            "                      estimator=Pipeline(memory='tmp',\n",
                            "                                         steps=[('selector',\n",
                            "                                                 VarianceThreshold()),\n",
                            "                                                ('scaler', MinMaxScaler()),\n",
                            "                                                ('rus', RandomUnderSampler()),\n",
                            "                                                ('pca', PCA()),\n",
                            "                                                ('clf', SVC())]),\n",
                            "                      n_jobs=-1,\n",
                            "                      param_distributions={'clf__C': [500],\n",
                            "                                           'clf__gamma': [1.1, 1, 0.9],\n",
                            "                                           'clf__kernel': ['rbf', 'poly',\n",
                            "                                                           'sigmoid',\n",
                            "                                                           'linear']},\n",
                            "                      scoring='f1_micro', verbose=1)"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.pipeline import Pipeline\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "from sklearn.experimental import enable_halving_search_cv\n",
                "from sklearn.model_selection import HalvingRandomSearchCV\n",
                "\n",
                "\n",
                "# Initialize the transformers without hyperparameters\n",
                "selector = VarianceThreshold()\n",
                "scaler = MinMaxScaler()\n",
                "rus = RandomUnderSampler()\n",
                "pca = PCA()\n",
                "\n",
                "# Initialize the pipeline\n",
                "pipe_svc = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', pca), ('clf', SVC())], memory = 'tmp')\n",
                "\n",
                "# Define the hyperparameters\n",
                "param_grid_svc = {\n",
                "              'clf__C': [500], \n",
                "              'clf__gamma': [1.1, 1, 0.9],\n",
                "              'clf__kernel': ['rbf', 'poly', 'sigmoid', 'linear']} \n",
                "\n",
                "\n",
                "grid_svc = HalvingRandomSearchCV(pipe_svc, param_grid_svc, cv=10, n_jobs=-1, verbose=1, scoring='f1_micro')\n",
                "\n",
                "# Fit the grid search\n",
                "grid_svc.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "id": "bHz2LXaYdTxX"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.8467918622848201\n",
                        "{'clf__kernel': 'linear', 'clf__gamma': 0.9, 'clf__C': 500}\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "|          |   Accuracy |   F1 Score |\n",
                            "|:---------|-----------:|-----------:|\n",
                            "| Pipeline |    0.93229 |   0.932246 |"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHFCAYAAAAg3/mzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlF0lEQVR4nO3dfViVhf3H8Q8H5RwfAlQElGFUWmooOjCi2q8HWVTOpa1lWIJmtZqzFrkJpqCrxPXgrAvLpSh5NcvZrFWaZZS1GenScLrK0mm4DJC5gdDkyDnn90frdDHROKjnK/p+Xdf5w5v74Yt0xdv7vs99Qnw+n08AAABGHNYDAACA0xsxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwFQH6wFaw+v1au/evTrjjDMUEhJiPQ4AAGgFn8+nAwcOqHfv3nI4jnz+o13EyN69exUfH289BgAAaIM9e/boO9/5zhG/3i5i5IwzzpD01TcTHh5uPA0AAGiNuro6xcfH+3+PH0m7iJGvL82Eh4cTIwAAtDPfdosFN7ACAABTxAgAADBFjAAAAFPt4p4RAMCpzePx6NChQ9ZjIEAdO3ZUaGjoMe+HGAEAmPH5fKqsrNS///1v61HQRpGRkYqNjT2m54ARIwAAM1+HSHR0tDp37syDLdsRn8+nL7/8UtXV1ZKkXr16tXlfxAgAwITH4/GHSI8ePazHQRt06tRJklRdXa3o6Og2X7LhBlYAgImv7xHp3Lmz8SQ4Fl///I7lnh9iBABgiksz7dvx+PkRIwAAwBQxAgAATHEDKwDgpJOQuyqox9s9Z0RQj4fmODMCAEAblZWVKTQ0VCNGEDPHghgBAKCNiouLNXnyZL3zzjvau3ev2Rxut9vs2McDMQIAQBvU19dr+fLluvPOOzVixAiVlJQ0+/rLL7+sYcOGyeVyKSoqSqNHj/Z/rbGxUVOnTlV8fLycTqf69u2r4uJiSVJJSYkiIyOb7evFF19s9q6VmTNnasiQIVq0aJHOOussuVwuSdKaNWt0ySWXKDIyUj169NAPfvAD7dy5s9m+/vGPfygzM1Pdu3dXly5dlJKSog0bNmj37t1yOBx6//33m60/b948nXnmmfJ6vcf6V3ZE3DOCk1KwrxfD1m7XWOsREEwza60nOC5+//vfq3///jrvvPN088036+c//7ny8vIUEhKiVatWafTo0brvvvu0dOlSud1urV692r9tVlaWysrK9PjjjyspKUm7du1STU1NQMffsWOH/vCHP2jlypX+h401NDQoJydHgwcPVn19vfLz8zV69GiVl5fL4XCovr5el156qeLi4vTSSy8pNjZWmzdvltfrVUJCgtLT07VkyRKlpKT4j7NkyRKNHz9eDseJO39BjAAA0AbFxcW6+eabJUlXXXWVamtr9fbbb+uyyy7Tgw8+qBtvvFGzZs3yr5+UlCRJ+uSTT/T73/9ea9euVXp6uiTp7LPPDvj4brdbS5cuVc+ePf3LfvSjHzVbZ/HixerZs6c+/PBDJSYmatmyZdq3b5/+8pe/qHv37pKkvn37+te/9dZbdccdd2ju3LlyOp3avHmztm7dqj/+8Y8BzxcILtMAABCg7du3a+PGjcrMzJQkdejQQWPGjPFfaikvL9fw4cNb3La8vFyhoaG69NJLj2mGM888s1mISNKnn36qzMxMnX322QoPD1dCQoIkqaKiwn/soUOH+kPkf40aNUqhoaF64YUXJH11yejyyy/37+dE4cwIAAABKi4uVlNTk3r37u1f5vP55HQ6VVRU5P/MlpYc7WuS5HA45PP5mi1r6VHrXbp0OWzZyJEjdeaZZ2rhwoXq3bu3vF6vEhMT/Te4ftuxw8LClJWVpSVLlui6667TsmXL9Nhjjx11m+OBMyMAAASgqalJS5cu1aOPPqry8nL/a8uWLerdu7eeffZZDR48WKWlpS1uP2jQIHm9Xr399tstfr1nz546cOCAGhoa/MvKy8u/da5//vOf2r59u6ZPn67hw4drwIAB+te//tVsncGDB6u8vFz79+8/4n5uvfVWvfHGG3riiSfU1NSk66677luPfaw4MwIAQABeeeUV/etf/9LEiRMVERHR7Gs/+tGPVFxcrIcffljDhw/XOeecoxtvvFFNTU1avXq1pk6dqoSEBGVnZ+uWW27x38D62Wefqbq6WjfccINSU1PVuXNnTZs2TXfddZc2bNhw2Dt1WtKtWzf16NFDTz31lHr16qWKigrl5uY2WyczM1OzZ8/WqFGjVFhYqF69eumDDz5Q7969lZaWJkkaMGCALrzwQk2dOlW33HLLt55NOR6IEQDASedkfiJqcXGx0tPTDwsR6asYeeihh9S9e3etWLFC999/v+bMmaPw8HD93//9n3+9J598UtOmTdNPf/pT/fOf/1SfPn00bdo0SVL37t31zDPP6Be/+IUWLlyo4cOHa+bMmbr99tuPOpfD4dBzzz2nu+66S4mJiTrvvPP0+OOP67LLLvOvExYWptdff1333nuvrrnmGjU1NWngwIGaP39+s31NnDhR7777rm655ZZj+JtqvRDf/16YOgnV1dUpIiJCtbW1Cg8Ptx4HQcBbe08vvLX3NPPft/YePHhQu3btavacDJwc7r//fq1YsUJ//etfv3Xdo/0cW/v7m3tGAACApK8e5LZt2zYVFRVp8uTJQTsuMQIAACRJP/vZz5ScnKzLLrssaJdoJO4ZAQAA/1VSUtKqm2WPN86MAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMMVbewEAJ5+Zhz9q/cQerzag1cePH6+nn376sOWffvqp+vbtq3feeUcPP/ywNm3apC+++EIvvPCCRo0addR9ejwePfzwwyopKdFnn32mTp06qV+/frrtttt06623BjRfe0OMAADQBldddZWWLFnSbFnPnj0lSQ0NDUpKStItt9zS6k+9nTVrln7729+qqKhIKSkpqqur0/vvv3/YJ+8eT263W2FhYSds/63FZRoAANrA6XQqNja22Ss0NFSSdPXVV+uBBx7Q6NGjW72/l156ST/96U/14x//WGeddZaSkpI0ceJETZkyxb+O1+vVQw89pL59+8rpdKpPnz568MEH/V/funWrrrjiCnXq1Ek9evTQ7bffrvr6ev/Xx48fr1GjRunBBx9U7969dd5550mS9uzZoxtuuEGRkZHq3r27rr32Wu3evfsY/4ZajxgBAOAkEBsbqzfffFP79u074jp5eXmaM2eOZsyYoQ8//FDLli1TTEyMpK/OxmRkZKhbt276y1/+ohUrVuiNN97Qz372s2b7KC0t1fbt27V27Vq98sorOnTokDIyMnTGGWfoT3/6k9avX6+uXbvqqquuktvtPqHf89e4TAMAQBu88sor6tq1q//PV199tVasWNHm/c2dO1fXX3+9YmNjdf755+uiiy7Stddeq6uvvlqSdODAAT322GMqKipSdna2JOmcc87RJZdcIklatmyZDh48qKVLl6pLly6SpKKiIo0cOVK//vWv/dHSpUsXLVq0yH955plnnpHX69WiRYsUEhIiSVqyZIkiIyO1bt06XXnllW3+nlqLGAEAoA0uv/xyPfnkk/4/fx0AbTVw4EBt27ZNmzZt0vr16/XOO+9o5MiRGj9+vBYtWqSPPvpIjY2NGj58eIvbf/TRR0pKSmo2x8UXXyyv16vt27f7Y2TQoEHN7hPZsmWLduzYoTPOOKPZ/g4ePKidO3ce0/fUWsQIAABt0KVLF/Xt2/e47tPhcGjYsGEaNmyYfv7zn+uZZ57RuHHjdN9996lTp07H5Rj/G0319fVKTk7W7373u8PW/fqG3BONe0YAADhJDRw4UNJX94P069dPnTp1UmlpaYvrDhgwQFu2bFFDQ4N/2fr16+VwOPw3qrbku9/9rj799FNFR0erb9++zV4REcF5izUxAgDAcVZfX6/y8nKVl5dLknbt2qXy8nJVVFQccZvrr79ev/nNb7RhwwZ99tlnWrdunSZNmqRzzz1X/fv3l8vl0tSpU/XLX/5SS5cu1c6dO/Xee++puLhYknTTTTfJ5XIpOztb27Zt01tvvaXJkydr3Lhx/ks0LbnpppsUFRWla6+9Vn/605+0a9curVu3TnfddZf+8Y9/HNe/lyMhRgAAOM7ef/99DR06VEOHDpUk5eTkaOjQocrPzz/iNhkZGXr55Zc1cuRInXvuucrOzlb//v31+uuvq0OHr+6qmDFjhu69917l5+drwIABGjNmjKqrqyVJnTt31muvvab9+/dr2LBhuv766zV8+HAVFRUdddbOnTvrnXfeUZ8+fXTddddpwIABmjhxog4ePKjw8PDj9DdydCE+n88XlCMdg7q6OkVERKi2tjZofzGwlZC7ynoEBNFu11jrERBM/33a6cGDB7Vr1y6dddZZcrlcxkOhrY72c2zt72/OjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAwJTX67UeAcfgePz8eBw8AMBEWFiYHA6H9u7dq549eyosLMz/QW04+fl8Prndbu3bt08Oh6PZ590EihgBAJhwOBw666yz9MUXX2jv3r3W46CNOnfurD59+sjhaPvFFmIEAGAmLCxMffr0UVNTkzwej/U4CFBoaKg6dOhwzGe0iBEAgKmQkBB17NhRHTt2tB4FRriBFQAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAqTbFyPz585WQkCCXy6XU1FRt3LjxqOvPmzdP5513njp16qT4+Hjdc889OnjwYJsGBgAAp5aAY2T58uXKyclRQUGBNm/erKSkJGVkZKi6urrF9ZctW6bc3FwVFBToo48+UnFxsZYvX65p06Yd8/AAAKD9CzhG5s6dq9tuu00TJkzQwIEDtWDBAnXu3FmLFy9ucf13331XF198scaOHauEhARdeeWVyszM/NazKQAA4PQQUIy43W5t2rRJ6enp3+zA4VB6errKyspa3Oaiiy7Spk2b/PHx97//XatXr9Y111xzxOM0Njaqrq6u2QsAAJyaAvqgvJqaGnk8HsXExDRbHhMTo48//rjFbcaOHauamhpdcskl8vl8ampq0h133HHUyzSFhYWaNWtWIKMBAIB26oS/m2bdunWaPXu2nnjiCW3evFkrV67UqlWrdP/99x9xm7y8PNXW1vpfe/bsOdFjAgAAIwGdGYmKilJoaKiqqqqaLa+qqlJsbGyL28yYMUPjxo3TrbfeKkkaNGiQGhoadPvtt+u+++6Tw3F4DzmdTjmdzkBGAwAA7VRAZ0bCwsKUnJys0tJS/zKv16vS0lKlpaW1uM2XX355WHCEhoZKknw+X6DzAgCAU0xAZ0YkKScnR9nZ2UpJSdEFF1ygefPmqaGhQRMmTJAkZWVlKS4uToWFhZKkkSNHau7cuRo6dKhSU1O1Y8cOzZgxQyNHjvRHCQAAOH0FHCNjxozRvn37lJ+fr8rKSg0ZMkRr1qzx39RaUVHR7EzI9OnTFRISounTp+vzzz9Xz549NXLkSD344IPH77sAAADtVoivHVwrqaurU0REhGpraxUeHm49DoIgIXeV9QgIot2usdYjIJhm1lpPgCBp7e9vPpsGAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmGpTjMyfP18JCQlyuVxKTU3Vxo0bj7r+v//9b02aNEm9evWS0+nUueeeq9WrV7dpYAAAcGrpEOgGy5cvV05OjhYsWKDU1FTNmzdPGRkZ2r59u6Kjow9b3+126/vf/76io6P1/PPPKy4uTp999pkiIyOPx/wAAKCdCzhG5s6dq9tuu00TJkyQJC1YsECrVq3S4sWLlZube9j6ixcv1v79+/Xuu++qY8eOkqSEhISjHqOxsVGNjY3+P9fV1QU6JgAAaCcCukzjdru1adMmpaenf7MDh0Pp6ekqKytrcZuXXnpJaWlpmjRpkmJiYpSYmKjZs2fL4/Ec8TiFhYWKiIjwv+Lj4wMZEwAAtCMBxUhNTY08Ho9iYmKaLY+JiVFlZWWL2/z973/X888/L4/Ho9WrV2vGjBl69NFH9cADDxzxOHl5eaqtrfW/9uzZE8iYAACgHQn4Mk2gvF6voqOj9dRTTyk0NFTJycn6/PPP9fDDD6ugoKDFbZxOp5xO54keDQAAnAQCipGoqCiFhoaqqqqq2fKqqirFxsa2uE2vXr3UsWNHhYaG+pcNGDBAlZWVcrvdCgsLa8PYAADgVBHQZZqwsDAlJyertLTUv8zr9aq0tFRpaWktbnPxxRdrx44d8nq9/mWffPKJevXqRYgAAIDAnzOSk5OjhQsX6umnn9ZHH32kO++8Uw0NDf5312RlZSkvL8+//p133qn9+/fr7rvv1ieffKJVq1Zp9uzZmjRp0vH7LgAAQLsV8D0jY8aM0b59+5Sfn6/KykoNGTJEa9as8d/UWlFRIYfjm8aJj4/Xa6+9pnvuuUeDBw9WXFyc7r77bk2dOvX4fRcAAKDdCvH5fD7rIb5NXV2dIiIiVFtbq/DwcOtxEAQJuausR0AQ7XaNtR4BwTSz1noCBElrf3/z2TQAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATLUpRubPn6+EhAS5XC6lpqZq48aNrdruueeeU0hIiEaNGtWWwwIAgFNQwDGyfPly5eTkqKCgQJs3b1ZSUpIyMjJUXV191O12796tKVOm6Hvf+16bhwUAAKeegGNk7ty5uu222zRhwgQNHDhQCxYsUOfOnbV48eIjbuPxeHTTTTdp1qxZOvvss49pYAAAcGoJKEbcbrc2bdqk9PT0b3bgcCg9PV1lZWVH3O5Xv/qVoqOjNXHixFYdp7GxUXV1dc1eAADg1BRQjNTU1Mjj8SgmJqbZ8piYGFVWVra4zZ///GcVFxdr4cKFrT5OYWGhIiIi/K/4+PhAxgQAAO3ICX03zYEDBzRu3DgtXLhQUVFRrd4uLy9PtbW1/teePXtO4JQAAMBSh0BWjoqKUmhoqKqqqpotr6qqUmxs7GHr79y5U7t379bIkSP9y7xe71cH7tBB27dv1znnnHPYdk6nU06nM5DRAABAOxXQmZGwsDAlJyertLTUv8zr9aq0tFRpaWmHrd+/f39t3bpV5eXl/tcPf/hDXX755SovL+fyCwAACOzMiCTl5OQoOztbKSkpuuCCCzRv3jw1NDRowoQJkqSsrCzFxcWpsLBQLpdLiYmJzbaPjIyUpMOWAwCA01PAMTJmzBjt27dP+fn5qqys1JAhQ7RmzRr/Ta0VFRVyOHiwKwAAaJ0Qn8/nsx7i29TV1SkiIkK1tbUKDw+3HgdBkJC7ynoEBNFu11jrERBMM2utJ0CQtPb3N6cwAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgKk2xcj8+fOVkJAgl8ul1NRUbdy48YjrLly4UN/73vfUrVs3devWTenp6UddHwAAnF4CjpHly5crJydHBQUF2rx5s5KSkpSRkaHq6uoW11+3bp0yMzP11ltvqaysTPHx8bryyiv1+eefH/PwAACg/Qvx+Xy+QDZITU3VsGHDVFRUJEnyer2Kj4/X5MmTlZub+63bezwedevWTUVFRcrKympxncbGRjU2Nvr/XFdXp/j4eNXW1io8PDyQcdFOJeSush4BQbTbNdZ6BATTzFrrCRAkdXV1ioiI+Nbf3wGdGXG73dq0aZPS09O/2YHDofT0dJWVlbVqH19++aUOHTqk7t27H3GdwsJCRURE+F/x8fGBjAkAANqRgGKkpqZGHo9HMTExzZbHxMSosrKyVfuYOnWqevfu3Sxo/ldeXp5qa2v9rz179gQyJgAAaEc6BPNgc+bM0XPPPad169bJ5XIdcT2n0ymn0xnEyQAAgJWAYiQqKkqhoaGqqqpqtryqqkqxsbFH3faRRx7RnDlz9MYbb2jw4MGBTwoAAE5JAV2mCQsLU3JyskpLS/3LvF6vSktLlZaWdsTtHnroId1///1as2aNUlJS2j4tAAA45QR8mSYnJ0fZ2dlKSUnRBRdcoHnz5qmhoUETJkyQJGVlZSkuLk6FhYWSpF//+tfKz8/XsmXLlJCQ4L+3pGvXruratetx/FYAAEB7FHCMjBkzRvv27VN+fr4qKys1ZMgQrVmzxn9Ta0VFhRyOb064PPnkk3K73br++uub7aegoEAzZ848tukBAEC7F/BzRiy09n3KOHXwnJHTC88ZOc3wnJHTxgl5zggAAMDxRowAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFPECAAAMEWMAAAAU8QIAAAwRYwAAABTxAgAADBFjAAAAFNtipH58+crISFBLpdLqamp2rhx41HXX7Fihfr37y+Xy6VBgwZp9erVbRoWAACcegKOkeXLlysnJ0cFBQXavHmzkpKSlJGRoerq6hbXf/fdd5WZmamJEyfqgw8+0KhRozRq1Cht27btmIcHAADtX4jP5/MFskFqaqqGDRumoqIiSZLX61V8fLwmT56s3Nzcw9YfM2aMGhoa9Morr/iXXXjhhRoyZIgWLFjQqmPW1dUpIiJCtbW1Cg8PD2RctFMJuausR0AQ7XaNtR4BwTSz1noCBElrf393CGSnbrdbmzZtUl5enn+Zw+FQenq6ysrKWtymrKxMOTk5zZZlZGToxRdfPOJxGhsb1djY6P9zbe1X/+HW1dUFMi7aMW/jl9YjIIjqQgL6NxHaO/5fftr4+vf2t533CChGampq5PF4FBMT02x5TEyMPv744xa3qaysbHH9ysrKIx6nsLBQs2bNOmx5fHx8IOMCaCcirAdAcM3hJ366OXDggCIijvxzDyhGgiUvL6/Z2RSv16v9+/erR48eCgkJMZwMwPFWV1en+Ph47dmzh8uwwCnG5/PpwIED6t2791HXCyhGoqKiFBoaqqqqqmbLq6qqFBsb2+I2sbGxAa0vSU6nU06ns9myyMjIQEYF0M6Eh4cTI8Ap6GhnRL4W0LtpwsLClJycrNLSUv8yr9er0tJSpaWltbhNWlpas/Ulae3atUdcHwAAnF4CvkyTk5Oj7OxspaSk6IILLtC8efPU0NCgCRMmSJKysrIUFxenwsJCSdLdd9+tSy+9VI8++qhGjBih5557Tu+//76eeuqp4/udAACAdingGBkzZoz27dun/Px8VVZWasiQIVqzZo3/JtWKigo5HN+ccLnooou0bNkyTZ8+XdOmTVO/fv304osvKjEx8fh9FwDaLafTqYKCgsMuzQI4fQT8nBEAAIDjic+mAQAApogRAABgihgBAACmiBEAAGCKGAEAAKaIEQAAYIoYAQAApogRACZ27typ6dOnKzMzU9XV1ZKkV199VX/729+MJwMQbMQIgKB7++23NWjQIG3YsEErV65UfX29JGnLli0qKCgwng5AsBEjAIIuNzdXDzzwgNauXauwsDD/8iuuuELvvfee4WQALBAjAIJu69atGj169GHLo6OjVVNTYzARAEvECICgi4yM1BdffHHY8g8++EBxcXEGEwGwRIwACLobb7xRU6dOVWVlpUJCQuT1erV+/XpNmTJFWVlZ1uMBCDI+tRdA0Lndbk2aNEklJSXyeDzq0KGDPB6Pxo4dq5KSEoWGhlqPCCCIiBEAZioqKrRt2zbV19dr6NCh6tevn/VIAAwQIwAAwFQH6wEAnH48Ho9KSkpUWlqq6upqeb3eZl9/8803jSYDYIEYARB0d999t0pKSjRixAglJiYqJCTEeiQAhrhMAyDooqKitHTpUl1zzTXWowA4CfDWXgBBFxYWpr59+1qPAeAkQYwACLp7771Xjz32mDgxC0DiMg0AA6NHj9Zbb72l7t276/zzz1fHjh2bfX3lypVGkwGwwA2sAIIuMjKyxc+mAXB64swIAAAwxT0jAADAFJdpAATFd7/7XZWWlqpbt24aOnToUZ8tsnnz5iBOBsAaMQIgKK699lo5nU5J0qhRo2yHAXBS4Z4RAABgintGAACAKS7TAAiKbt26tfozaPbv33+CpwFwMiFGAATFvHnzrEcAcJLinhEAAGCKe0YAmNi5c6emT5+uzMxMVVdXS5JeffVV/e1vfzOeDECwESMAgu7tt9/WoEGDtGHDBq1cuVL19fWSpC1btqigoMB4OgDBRowACLrc3Fw98MADWrt2rcLCwvzLr7jiCr333nuGkwGwQIwACLqtW7e2+EF50dHRqqmpMZgIgCViBEDQRUZG6osvvjhs+QcffKC4uDiDiQBYIkYABN2NN96oqVOnqrKyUiEhIfJ6vVq/fr2mTJmirKws6/EABBlv7QUQdG63W5MmTVJJSYk8Ho86dOggj8ejsWPHqqSkRKGhodYjAggiYgSAmYqKCm3btk319fUaOnSo+vXrZz0SAAPECABTX/8vqLWPigdw6uGeEQAmiouLlZiYKJfLJZfLpcTERC1atMh6LAAG+GwaAEGXn5+vuXPnavLkyUpLS5MklZWV6Z577lFFRYV+9atfGU8IIJi4TAMg6Hr27KnHH39cmZmZzZY/++yzmjx5Ms8aAU4zXKYBEHSHDh1SSkrKYcuTk5PV1NRkMBEAS8QIgKAbN26cnnzyycOWP/XUU7rpppsMJgJgics0AIJu8uTJWrp0qeLj43XhhRdKkjZs2KCKigplZWWpY8eO/nXnzp1rNSaAICFGAATd5Zdf3qr1QkJC9Oabb57gaQBYI0YAAIAp7hkBAACmeM4IgKC47rrrVFJSovDwcI0ePfqoT1xduXJlECcDYI0YARAUERER/gCJjIxUSEiIuEoMQOKeEQBB5PF49Mgjj+ill16S2+3WFVdcoZkzZ6pTp07WowEwxD0jAIJm9uzZmjZtmrp27aq4uDg9/vjjmjRpkvVYAIxxZgRA0PTr109TpkzRT37yE0nSG2+8oREjRug///mPHA7+bQScrogRAEHjdDq1Y8cOxcfH+5e5XC7t2LFD3/nOdwwnA2CJf4oACJqmpia5XK5myzp27KhDhw4ZTQTgZMC7aQAEjc/n0/jx4+V0Ov3LDh48qDvuuENdunTxL+OtvcDphRgBEDTZ2dmHLbv55psNJgFwMuGeEQAAYIp7RgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgKn/B76dxEW2iIaIAAAAAElFTkSuQmCC",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
                "grid_svc_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
                "y_pred = grid_svc.best_estimator_.predict(X_test)\n",
                "grid_svc_df.loc[grid_svc.best_estimator_.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
                "\n",
                "\n",
                "print(grid_svc.best_score_)\n",
                "print(grid_svc.best_params_)\n",
                "\n",
                "from IPython.display import Markdown as md\n",
                "\n",
                "\n",
                "# display the results of the classifiers in a comparison bar plot\n",
                "comparisonBarPlot = grid_svc_df.plot.bar()\n",
                "\n",
                "# display the results of the classifiers in a markdown table\n",
                "markDownTableResults = grid_svc_df.to_markdown()\n",
                "md(markDownTableResults)# # # # # # # # # # # "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "WTvhS2V5tzMd",
                "outputId": "2354e6bb-c9dc-4748-911b-2607cc209cc2"
            },
            "outputs": [],
            "source": [
                "import optuna\n",
                "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from imblearn.under_sampling import RandomUnderSampler \n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from imblearn.pipeline import Pipeline\n",
                "from sklearn.model_selection import cross_val_score\n",
                "import numpy as np\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "\n",
                "# -- Define the objective function\n",
                "def objective(trial):\n",
                "\n",
                "    # -- Instantiate selector\n",
                "    selector_threshold = trial.suggest_float('selector__threshold', 0.0, 0.1)\n",
                "\n",
                "    selector = VarianceThreshold(threshold=selector_threshold)\n",
                "\n",
                "    # -- Instantiate UnderSampler\n",
                "    rus = RandomUnderSampler()\n",
                "\n",
                "    # -- Instantiate scaler\n",
                "    # (a) List scalers to chose from\n",
                "    scalers = trial.suggest_categorical(\"scalers\", ['minmax', 'standard'])\n",
                "\n",
                "    # (b) Define your scalers\n",
                "    if scalers == \"minmax\":\n",
                "        scaler = MinMaxScaler()\n",
                "    elif scalers == \"standard\":\n",
                "        scaler = StandardScaler()\n",
                "\n",
                "    # -- Instantiate dimensionality reduction\n",
                "     # (a) List all dimensionality reduction options\n",
                "    dim_red = trial.suggest_categorical(\"dim_red\", [\"PCA\", None])\n",
                "\n",
                "    # (b) Define the PCA algorithm and its hyperparameters\n",
                "    if dim_red == \"PCA\":\n",
                "        pca_n_components=trial.suggest_int(\"pca_n_components\", 50, 171)\n",
                "        dimen_red_algorithm=PCA(n_components=pca_n_components)\n",
                "    # (c) No dimensionality reduction option\n",
                "    else:\n",
                "        dimen_red_algorithm='passthrough'\n",
                "\n",
                "\n",
                "   # -- Instantiate estimator model\n",
                "    C=trial.suggest_float('clf__C', 0.5, 1000.0)\n",
                "    kernel=trial.suggest_categorical('clf__kernel', ['rbf', 'poly', 'sigmoid', 'linear'])\n",
                "    gamma=trial.suggest_float('clf__gamma', 0.001,1)\n",
                "\n",
                "    estimator = SVC(C=C, kernel=kernel, gamma=gamma)\n",
                "\n",
                "    ##########\n",
                "\n",
                "\n",
                "    # -- Make a pipeline\n",
                "    pipeline = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus), ('pca', dimen_red_algorithm), ('clf', estimator)], memory = 'tmp')\n",
                "\n",
                "    # -- Evaluate the score by cross-validation\n",
                "    score = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=5)\n",
                "    acc = score.mean() # calculate the mean of scores\n",
                "    return acc\n",
                "\n",
                "study = optuna.create_study(direction=\"maximize\") # maximise the score during tuning\n",
                "study.optimize(objective, n_trials=20) # run the objective function 20 times\n",
                "\n",
                "print(study.best_trial) # print the best performing pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/markdown": [
                            "|          |   Accuracy |   F1 Score |\n",
                            "|:---------|-----------:|-----------:|\n",
                            "| Pipeline |   0.921717 |   0.921722 |"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# parameters: {'selector__threshold': 0.004018792290066309, 'scalers': 'minmax', 'dim_red': None, 'clf__C': 272.19639794978974, 'clf__kernel': 'linear', 'clf__gamma': 0.20803325037611617}.\n",
                "\n",
                "\n",
                "from imblearn.under_sampling import RandomUnderSampler\n",
                "from imblearn.pipeline import Pipeline\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "\n",
                "# Initialize the transformers without hyperparameters\n",
                "selector = VarianceThreshold(threshold=0.004018792290066309)\n",
                "scaler = MinMaxScaler()\n",
                "rus = RandomUnderSampler()\n",
                "\n",
                "# Initialize the pipeline\n",
                "pipe_svc_optuna = Pipeline([('selector', selector), ('scaler', scaler), ('rus', rus),  ('clf', SVC(C=272.19639794978974,kernel=\"linear\", gamma=0.20803325037611617))], memory = 'tmp')\n",
                "\n",
                "\n",
                "# Fit the grid search\n",
                "pipe_svc_optuna.fit(X_train, y_train)\n",
                "\n",
                "\n",
                "# # # fit the classifiers and print the accuracy and f1 score for each classifier and save them in a dataframe\n",
                "pipe_svc_optuna_df = pd.DataFrame(columns=['Accuracy', 'F1 Score'])\n",
                "y_pred = pipe_svc_optuna.predict(X_test)\n",
                "pipe_svc_optuna_df.loc[pipe_svc_optuna.__class__.__name__] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='weighted')]\n",
                "\n",
                "\n",
                "\n",
                "from IPython.display import Markdown as md\n",
                "\n",
                "\n",
                "# display the results of the classifiers in a comparison bar plot\n",
                "comparisonBarPlot = pipe_svc_optuna_df.plot.bar()\n",
                "\n",
                "# display the results of the classifiers in a markdown table\n",
                "markDownTableResults = pipe_svc_optuna_df.to_markdown()\n",
                "md(markDownTableResults)# # # # # # # # # # # \n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### **Conclusion for SVM:**\n",
                "\n",
                "Results |   Accuracy | \tF1 Score |\n",
                "----------- | ----------- | ----------- |\n",
                "Out of the box |\t0.838673 |\t0.812597 |\n",
                "Hyperparameter Optimization |\t0.93229 |\t0.932246  |\n",
                "Optuna |\t0.921717 |\t0.921722 |\n",
                "\n",
                "As we can see, we achieved considerable increases in performance by using hyperparameter optimization. The manual hyperparameter optimization was the most effective and produced the best model. That would be our selection for the best SVM estimator for our final model."
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3.10.8 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        },
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
